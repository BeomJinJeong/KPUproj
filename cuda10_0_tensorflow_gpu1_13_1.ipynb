{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "cuda10.0/tensorflow-gpu1.13.1",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "13M-DTPC37jCcfRnEAEqvihqNm29-7nuO",
      "authorship_tag": "ABX9TyOCTI2nNXrCTK0uljfYbU6D",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/BeomJinJeong/KPUproj/blob/master/cuda10_0_tensorflow_gpu1_13_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "twVDt4KefRn4"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zB9zLOFJrWN0"
      },
      "source": [
        "!pip install tensorflow-gpu==1.13.1\n",
        "!apt-get --purge remove \"*cublas*\" \"cuda*\"\n",
        "!reboot\n",
        "!wget https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64/cuda-repo-ubuntu1804_10.0.130-1_amd64.deb\n",
        "!dpkg -i cuda-repo-ubuntu1804_10.0.130-1_amd64.deb\n",
        "!sudo apt-key adv --fetch-keys https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64/7fa2af80.pub\n",
        "!apt install cuda-10-0\n",
        "!reboot\n",
        "!pip install ffmpeg-python\n",
        "!sudo pip install --upgrade youtube_dl\n",
        "!pip install flask-ngrok\n",
        "!pip install pafy"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-C5AtCex5Qo9"
      },
      "source": [
        "## visualize_cv2.py ▼"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T2AeslbqN50B",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 264
        },
        "outputId": "ea400890-e109-4b8c-e959-f5a9475ae084"
      },
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import os\n",
        "import sys\n",
        "from mrcnn import utils\n",
        "from mrcnn import model as modellib\n",
        "\n",
        "os.chdir(\"/content/drive/My Drive/Colab Notebooks/MRCNN_pure\")\n",
        "sys.path.append(\"/content/drive/My Drive/Colab Notebooks/MRCNN_pure\")\n",
        "ROOT_DIR = os.getcwd()\n",
        "MODEL_DIR = os.path.join(ROOT_DIR, \"logs\")\n",
        "\n",
        "# Import COCO config\n",
        "sys.path.append(os.path.join(ROOT_DIR, \"samples/coco  /\"))  # To find local version\n",
        "import coco\n",
        "\n",
        "COCO_MODEL_PATH = os.path.join(ROOT_DIR, \"mask_rcnn_coco.h5\")\n",
        "if not os.path.exists(COCO_MODEL_PATH):\n",
        "    utils.download_trained_weights(COCO_MODEL_PATH)\n",
        "\n",
        "\n",
        "class InferenceConfig(coco.CocoConfig):\n",
        "    GPU_COUNT = 1\n",
        "    IMAGES_PER_GPU = 1\n",
        "\n",
        "\n",
        "config = InferenceConfig()\n",
        "config.display()\n",
        "\n",
        "model = modellib.MaskRCNN(\n",
        "    mode=\"inference\", model_dir=MODEL_DIR, config=config\n",
        ")\n",
        "model.load_weights(COCO_MODEL_PATH, by_name=True)\n",
        "class_names = [\n",
        "    'BG', 'person', 'bicycle', 'car', 'motorcycle', 'airplane',\n",
        "    'bus', 'train', 'truck', 'boat', 'traffic light',\n",
        "    'fire hydrant', 'stop sign', 'parking meter', 'bench', 'bird',\n",
        "    'cat', 'dog', 'horse', 'sheep', 'cow', 'elephant', 'bear',\n",
        "    'zebra', 'giraffe', 'backpack', 'umbrella', 'handbag', 'tie',\n",
        "    'suitcase', 'frisbee', 'skis', 'snowboard', 'sports ball',\n",
        "    'kite', 'baseball bat', 'baseball glove', 'skateboard',\n",
        "    'surfboard', 'tennis racket', 'bottle', 'wine glass', 'cup',\n",
        "    'fork', 'knife', 'spoon', 'bowl', 'banana', 'apple',\n",
        "    'sandwich', 'orange', 'broccoli', 'carrot', 'hot dog', 'pizza',\n",
        "    'donut', 'cake', 'chair', 'couch', 'potted plant', 'bed',\n",
        "    'dining table', 'toilet', 'tv', 'laptop', 'mouse', 'remote',\n",
        "    'keyboard', 'cell phone', 'microwave', 'oven', 'toaster',\n",
        "    'sink', 'refrigerator', 'book', 'clock', 'vase', 'scissors',\n",
        "    'teddy bear', 'hair drier', 'toothbrush'\n",
        "]\n",
        "\n",
        "\n",
        "def random_colors(N):\n",
        "    np.random.seed(1)\n",
        "    colors = [tuple(255 * np.random.rand(3)) for _ in range(N)]\n",
        "    return colors\n",
        "\n",
        "\n",
        "colors = random_colors(len(class_names))\n",
        "class_dict = {\n",
        "    name: color for name, color in zip(class_names, colors)\n",
        "}\n",
        "\n",
        "\n",
        "def apply_mask(image, mask, color, alpha=0.5):\n",
        "    \"\"\"apply mask to image\"\"\"\n",
        "    for n, c in enumerate(color):\n",
        "        image[:, :, n] = np.where(\n",
        "            mask == 1,\n",
        "            image[:, :, n] * (1 - alpha) + alpha * c,\n",
        "            image[:, :, n]\n",
        "        )\n",
        "    return image\n",
        "\n",
        "\n",
        "def display_instances(image, boxes, masks, ids, names, scores):\n",
        "    \"\"\"\n",
        "        take the image and results and apply the mask, box, and Label\n",
        "    \"\"\"\n",
        "    n_instances = boxes.shape[0]\n",
        "\n",
        "    if not n_instances:\n",
        "        print('NO INSTANCES TO DISPLAY')\n",
        "    else:\n",
        "        assert boxes.shape[0] == masks.shape[-1] == ids.shape[0]\n",
        "\n",
        "    for i in range(n_instances):\n",
        "        if not np.any(boxes[i]):\n",
        "            continue\n",
        "\n",
        "        y1, x1, y2, x2 = boxes[i]\n",
        "        label = names[ids[i]]\n",
        "        color = class_dict[label]\n",
        "        score = scores[i] if scores is not None else None\n",
        "        caption = '{} {:.2f}'.format(label, score) if score else label\n",
        "        mask = masks[:, :, i]\n",
        "\n",
        "        image = apply_mask(image, mask, color)\n",
        "        image = cv2.rectangle(image, (x1, y1), (x2, y2), color, 2)\n",
        "        image = cv2.putText(\n",
        "            image, caption, (x1, y1), cv2.FONT_HERSHEY_COMPLEX, 0.7, color, 2\n",
        "        )\n",
        "\n",
        "    return image\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    \"\"\"\n",
        "        test everything\n",
        "    \"\"\"\n",
        "\n",
        "    capture = cv2.VideoCapture(0)\n",
        "\n",
        "    # these 2 lines can be removed if you dont have a 1080p camera.\n",
        "    capture.set(cv2.CAP_PROP_FRAME_WIDTH, 1920)\n",
        "    capture.set(cv2.CAP_PROP_FRAME_HEIGHT, 1080)\n",
        "\n",
        "    while True:\n",
        "        ret, frame = capture.read()\n",
        "        results = model.detect([frame], verbose=0)\n",
        "        r = results[0]\n",
        "        frame = display_instances(\n",
        "            frame, r['rois'], r['masks'], r['class_ids'], class_names, r['scores']\n",
        "        )\n",
        "        cv2.imshow('frame', frame)\n",
        "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
        "            break\n",
        "\n",
        "    capture.release()\n",
        "    cv2.destroyAllWindows()"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[1;32m<ipython-input-1-7077ac330932>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mmrcnn\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmodel\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mmodellib\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchdir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"/content/drive/My Drive/Colab Notebooks/MRCNN_pure\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"/content/drive/My Drive/Colab Notebooks/MRCNN_pure\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[0mROOT_DIR\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetcwd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 3] 지정된 경로를 찾을 수 없습니다: '/content/drive/My Drive/Colab Notebooks/MRCNN_pure'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U6Z23Q9Uhp7D"
      },
      "source": [
        "### local-web(flask) threading"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xQmMwyrJ-QwO"
      },
      "source": [
        "import cv2\n",
        "import os\n",
        "import sys\n",
        "sys.path.append(\"/MRCNN_pure\")\n",
        "from visualize_cv2 import model, display_instances, class_names\n",
        "import argparse\n",
        "import threading\n",
        "from flask import Flask, render_template, Response\n",
        "\n",
        "capture = cv2.VideoCapture(1)\n",
        "\n",
        "outFrame = None\n",
        "isEmergency = \"false\"\n",
        "_lock = threading.Lock()\n",
        "\n",
        "app = Flask(__name__)\n",
        "\n",
        "@app.route(\"/\")\n",
        "def main():\n",
        "  return render_template('index.html')\n",
        "\n",
        "def webcam(capture):\n",
        "  global outFrame, _lock, isEmergency\n",
        "\n",
        "  while True:\n",
        "\n",
        "    grabbed, frame = capture.read()\n",
        "    if not grabbed:\n",
        "      print (\"Not grabbed.\")\n",
        "\n",
        "    results = model.detect([frame], verbose=1)\n",
        "    \n",
        "    # Visualize results\n",
        "    r = results[0]\n",
        "    masked_frame = display_instances(frame, r['rois'], r['masks'], r['class_ids'],\n",
        "                              class_names, r['scores'])\n",
        "    \n",
        "    with _lock:\n",
        "      outFrame = masked_frame.copy()\n",
        "      isEmergency = \"false\"\n",
        "\n",
        "def generate():\n",
        "\n",
        "    global outFrame, _lock\n",
        "\n",
        "    while True:\n",
        "      with _lock:\n",
        "        if outFrame is None:\n",
        "          continue\n",
        "        \n",
        "        encode_param=[int(cv2.IMWRITE_JPEG_QUALITY), 90]\n",
        "        (flag, encodedImage) = cv2.imencode(\".jpg\", outFrame, encode_param)\n",
        "        if not flag:\n",
        "          continue\n",
        "      \n",
        "      yield(b'--frame\\r\\n' b'Content-Type: image/jpeg\\r\\n\\r\\n' + bytearray(encodedImage) + b'\\r\\n')\n",
        "\n",
        "\n",
        "@app.route(\"/video_feed\")\n",
        "def video_feed():\n",
        "  return Response(generate(), mimetype = \"multipart/x-mixed-replace; boundary=frame\")\n",
        "\n",
        "\n",
        "def emergency():\n",
        "  from PIL import Image\n",
        "  isEme = cv2.imread('test1.jpg')\n",
        "  isEmerg = True\n",
        "\n",
        "  encode_param=[int(cv2.IMWRITE_JPEG_QUALITY), 90]\n",
        "  flag, encodedImage = cv2.imencode(\".jpg\", isEme, encode_param)\n",
        "  while True:\n",
        "    with _lock:\n",
        "      if isEmerg:\n",
        "        yield(b'--frame\\r\\n' b'Content-Type: image/jpeg\\r\\n\\r\\n' + bytearray(encodedImage) + b'\\r\\n')\n",
        "\n",
        "@app.route(\"/isEmg\")\n",
        "def isEmg():\n",
        "  return Response(emergency(), mimetype = \"multipart/x-mixed-replace; boundary=frame\")\n",
        "print('server start')\n",
        "\n",
        "def log_gen():\n",
        "  text1 = \"sibal\"\n",
        "  print(\"hi\")\n",
        "  yield text1\n",
        "    \n",
        "@app.route(\"/for_log\")\n",
        "def for_log():\n",
        "  print(\"hello\")\n",
        "  return Response(log_gen())\n",
        "\n",
        "def isEmg_whole():\n",
        "  global isEmergency\n",
        "  with _lock:\n",
        "    print(\"isEmg\")\n",
        "    yield isEmergency\n",
        "\n",
        "@app.route(\"/isEmergence\")\n",
        "def isEmergence():\n",
        "  return Response(isEmg_whole());\n",
        "\n",
        "args = sys.argv\n",
        "if(len(args) <2):\n",
        "  print(\"run command: python or video: file name\")\n",
        "  sys.exit(0) \n",
        "name = args[1]\n",
        "if(len(args[1]) == 0):\n",
        "  name = int(args[1])\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "  \n",
        "  threading.Thread(target=app.run).start()\n",
        "  threading.Thread(target=webcam(capture)).start()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tKB66fqfW2Z3",
        "outputId": "69206382-ce02-4fc6-d293-9563a50f9b69"
      },
      "source": [
        "!pip install flask"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: flask in c:\\users\\jeongbeomjin\\anaconda3\\envs\\opencv\\lib\\site-packages (1.1.2)\n",
            "Requirement already satisfied: Jinja2>=2.10.1 in c:\\users\\jeongbeomjin\\anaconda3\\envs\\opencv\\lib\\site-packages (from flask) (2.11.2)\n",
            "Requirement already satisfied: itsdangerous>=0.24 in c:\\users\\jeongbeomjin\\anaconda3\\envs\\opencv\\lib\\site-packages (from flask) (1.1.0)\n",
            "Requirement already satisfied: click>=5.1 in c:\\users\\jeongbeomjin\\anaconda3\\envs\\opencv\\lib\\site-packages (from flask) (7.1.2)\n",
            "Requirement already satisfied: Werkzeug>=0.15 in c:\\users\\jeongbeomjin\\anaconda3\\envs\\opencv\\lib\\site-packages (from flask) (0.16.1)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in c:\\users\\jeongbeomjin\\anaconda3\\envs\\opencv\\lib\\site-packages (from Jinja2>=2.10.1->flask) (1.1.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xxkp7Ziu8u_G"
      },
      "source": [
        "### Model - Web - Local threading"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sXwyhu6Ajbfq",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "ce45da1e-d128-49b1-f5eb-3f1926282fd5"
      },
      "source": [
        "import cv2\n",
        "import os\n",
        "import sys\n",
        "#sys.path.append(\"/MRCNN_pure\")\n",
        "#from visualize_cv2 import model, display_instances, class_names\n",
        "import argparse\n",
        "import threading\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from flask import Flask, render_template, Response\n",
        "\n",
        "os.chdir(\"/MRCNN_pure_02\")\n",
        "sys.path.append(\"/MRCNN_pure_02\")\n",
        "  \n",
        "# Root directory of the project\n",
        "ROOT_DIR = os.path.abspath(\".\")\n",
        "\n",
        "MAXIMUM_WEIGHT = 10\n",
        "layer = 255 * np.ones((500,500,3), dtype=np.uint8)\n",
        "layer_frame = 255 * np.ones((64,64,3), dtype=np.uint8)\n",
        "logo = cv2.imread(os.path.join(ROOT_DIR, \"siren_black.jpg\"))\n",
        "\n",
        "from keras.models import load_model\n",
        "mlp_model = load_model('/MRCNN_pure_02/mlp_model.h5')\n",
        "  \n",
        "# Import Mask RCNN\n",
        "sys.path.append(ROOT_DIR)  # To find local version of the library\n",
        "from mrcnn import utils\n",
        "import mrcnn.model as modellib\n",
        "# Import COCO config\n",
        "sys.path.append(os.path.join(ROOT_DIR, \"samples/coco/\"))  # To find local version\n",
        "import coco\n",
        "  \n",
        "# Directory to save logs and trained model\n",
        "MODEL_DIR = os.path.join(ROOT_DIR, \"logs\")\n",
        "  \n",
        "# Local path to trained weights file\n",
        "COCO_MODEL_PATH = os.path.join(ROOT_DIR, \"mask_rcnn_coco.h5\")\n",
        "# Download COCO trained weights from Releases if needed\n",
        "if not os.path.exists(COCO_MODEL_PATH):\n",
        "    utils.download_trained_weights(COCO_MODEL_PATH)\n",
        "  \n",
        "  \n",
        "class InferenceConfig(coco.CocoConfig):\n",
        "    # Set batch size to 1 since we'll be running inference on\n",
        "    # one image at a time. Batch size = GPU_COUNT * IMAGES_PER_GPU\n",
        "    GPU_COUNT = 1\n",
        "    IMAGES_PER_GPU = 1\n",
        "  \n",
        "config = InferenceConfig()\n",
        "config.display()\n",
        "  \n",
        "# Create model object in inference mode.\n",
        "model = modellib.MaskRCNN(mode=\"inference\", model_dir=MODEL_DIR, config=config)\n",
        "  \n",
        "# Load weights trained on MS-COCO\n",
        "model.load_weights(COCO_MODEL_PATH, by_name=True)\n",
        "  \n",
        "# COCO Class names\n",
        "# Index of the class in the list is its ID. For example, to get ID of\n",
        "# the teddy bear class, use: class_names.index('teddy bear')\n",
        "class_names = ['BG', 'person', 'bicycle', 'car', 'motorcycle', 'airplane',\n",
        "               'bus', 'train', 'truck', 'boat', 'traffic light',\n",
        "               'fire hydrant', 'stop sign', 'parking meter', 'bench', 'bird',\n",
        "               'cat', 'dog', 'horse', 'sheep', 'cow', 'elephant', 'bear',\n",
        "               'zebra', 'giraffe', 'backpack', 'umbrella', 'handbag', 'tie',\n",
        "               'suitcase', 'frisbee', 'skis', 'snowboard', 'sports ball',\n",
        "               'kite', 'baseball bat', 'baseball glove', 'skateboard',\n",
        "               'surfboard', 'tennis racket', 'bottle', 'wine glass', 'cup',\n",
        "               'fork', 'knife', 'spoon', 'bowl', 'banana', 'apple',\n",
        "               'sandwich', 'orange', 'broccoli', 'carrot', 'hot dog', 'pizza',\n",
        "               'donut', 'cake', 'chair', 'couch', 'potted plant', 'bed',\n",
        "               'dining table', 'toilet', 'tv', 'laptop', 'mouse', 'remote',\n",
        "               'keyboard', 'cell phone', 'microwave', 'oven', 'toaster',\n",
        "               'sink', 'refrigerator', 'book', 'clock', 'vase', 'scissors',\n",
        "               'teddy bear', 'hair drier', 'toothbrush']\n",
        "\n",
        "def random_colors(N):\n",
        "    np.random.seed(1)\n",
        "    colors = [tuple(255 * np.random.rand(3)) for _ in range(N)]\n",
        "    return colors\n",
        "\n",
        "colors = random_colors(len(class_names))\n",
        "class_dict = {\n",
        "    name: color for name, color in zip(class_names, colors)\n",
        "}\n",
        "\n",
        "def apply_mask(image, mask, color, alpha=0.5):\n",
        "    \"\"\"apply mask to image\"\"\"\n",
        "    for n, c in enumerate(color):\n",
        "        image[:, :, n] = np.where(\n",
        "            mask == 1,\n",
        "            image[:, :, n] * (1 - alpha) + alpha * c,\n",
        "            image[:, :, n]\n",
        "        )\n",
        "    return image\n",
        "\n",
        "def apply_mask2(image, mask, num=2):\n",
        "    image[:, :] = np.where(\n",
        "        mask == 1,\n",
        "        image[:, :] +num,\n",
        "        image[:, :]\n",
        "    )\n",
        "    return image    \n",
        "\n",
        "def img_overlay(background, logo, height, xpos, ypos):\n",
        "    logo_height = int(height / 7)\n",
        "    logo = cv2.resize(logo, (logo_height, logo_height))\n",
        "\n",
        "    gray_logo = cv2.cvtColor(logo, cv2.COLOR_BGR2GRAY)\n",
        "    _, mask_inv = cv2.threshold(gray_logo, 10, 255, cv2.THRESH_BINARY_INV)\n",
        "\n",
        "\n",
        "    background_height, background_width, _ = background.shape # 400, 520, 3\n",
        "    logo_height, logo_width, _ = logo.shape # 308, 250, 3\n",
        "\n",
        "    x = xpos\n",
        "    y = ypos\n",
        "\n",
        "    roi = background[x: x+logo_height, y: y+logo_width]\n",
        "\n",
        "    roi_logo = cv2.add(logo, roi, mask=mask_inv)\n",
        "    result = cv2.add(roi_logo, logo)\n",
        "    np.copyto(roi, result)\n",
        "    return background\n",
        "\n",
        "def display_instances(image, boxes, masks, ids, names, scores):\n",
        "    \"\"\"\n",
        "        take the image and results and apply the mask, box, and Label\n",
        "    \"\"\"\n",
        "    os.chdir(\"/MRCNN_pure\")\n",
        "    n_instances = boxes.shape[0]\n",
        "    isEmergency = 0\n",
        "    emergencyImage = image\n",
        "\n",
        "    if not n_instances:\n",
        "        print('NO INSTANCES TO DISPLAY')\n",
        "    else:\n",
        "        assert boxes.shape[0] == masks.shape[-1] == ids.shape[0]\n",
        "\n",
        "    for i in range(n_instances):\n",
        "        if not np.any(boxes[i]):\n",
        "            continue\n",
        "        if not (ids[i] == 1) :\n",
        "            continue\n",
        "        print('test27')\n",
        "        image = cv2.UMat(image)\n",
        "        image = cv2.UMat.get(image)\n",
        "        height = image.shape[0]\n",
        "        width = image.shape[1]\n",
        "\n",
        "        mask_list = []\n",
        "        y1, x1, y2, x2 = boxes[i]\n",
        "        label = names[ids[i]]\n",
        "        color = class_dict[label]\n",
        "        score = scores[i] if scores is not None else None\n",
        "        caption = '{} {:.2f}'.format(label, score) if score else label\n",
        "        mask = masks[:, :, i]\n",
        "        mask_list.append(mask)\n",
        "\n",
        "        global layer\n",
        "        global layer_frame\n",
        "        global weight_frame\n",
        "\n",
        "        black = [0, 0, 0]\n",
        "        red = [0, 0, 255]\n",
        "\n",
        "        weight_frame = apply_mask2(weight_frame, mask)\n",
        "        weight_frame[weight_frame>=MAXIMUM_WEIGHT] = MAXIMUM_WEIGHT\n",
        "\n",
        "\n",
        "        current_frame = np.zeros((height,width), dtype=np.uint8)\n",
        "        current_frame = apply_mask2(current_frame, mask, num = MAXIMUM_WEIGHT)\n",
        "        current_frame[current_frame==0] = 255\n",
        "\n",
        "        pixel_count = np.count_nonzero(current_frame==MAXIMUM_WEIGHT)\n",
        "        print(\"Current frame pixels : \", pixel_count)\n",
        "        same_pixel = np.count_nonzero(current_frame==weight_frame)\n",
        "        print(\"Same pixels: \", same_pixel)\n",
        "        frame_acc = same_pixel / pixel_count\n",
        "        print(\"Frame acc: \", frame_acc)\n",
        "\n",
        "        layer = 255 * np.ones((height,width,3), dtype=np.uint8)\n",
        "        layer = apply_mask(layer, mask, black, alpha=0.8)\n",
        "        layer = layer[y1:y2, x1:x2, :]\n",
        "        layer_height = layer.shape[0]\n",
        "        layer_width = layer.shape[1]\n",
        "        if(layer_height >= layer_width) :\n",
        "          scale_percent = 64 / layer_height\n",
        "          new_height = int(layer_height * scale_percent)\n",
        "          new_width = int(layer_width * scale_percent)\n",
        "          layer = cv2.resize(layer, dsize=(new_width, new_height), interpolation=cv2.INTER_CUBIC)\n",
        "          layer_frame = 255 * np.ones((64,64,3), dtype=np.uint8)\n",
        "          #layer_frame[0:new_width, 32-(new_height//2):32+(new_height//2),:] = layer\n",
        "          rows, cols, channels = layer.shape\n",
        "          layer_frame[0:rows, 32-(cols//2):32-(cols//2) + cols] = layer\n",
        "        else :\n",
        "          scale_percent = 64 / layer_width\n",
        "          new_height = int(layer_height * scale_percent)\n",
        "          new_width = int(layer_width * scale_percent)\n",
        "          layer = cv2.resize(layer, dsize=(new_width, new_height), interpolation=cv2.INTER_CUBIC)\n",
        "          layer_frame = 255 * np.ones((64,64,3), dtype=np.uint8)\n",
        "          #layer_frame[32-(new_width//2):32+(new_width//2), 0:new_height,:] = layer\n",
        "          rows, cols, channels = layer.shape\n",
        "          layer_frame[32-(rows//2):32-(rows//2) + rows, 0:cols] = layer\n",
        "\n",
        "        backup = layer_frame\n",
        "        layer_frame = cv2.cvtColor(layer_frame, cv2.COLOR_BGR2GRAY)\n",
        "        layer_frame = ~layer_frame\n",
        "\n",
        "        predict_test = layer_frame\n",
        "        predict_test = predict_test.reshape(1, 4096)\n",
        "\n",
        "        result = mlp_model.predict(predict_test)\n",
        "        label_index = np.argmax(result)\n",
        "\n",
        "        rows, cols = np.where(weight_frame >= 10)\n",
        "        print(rows, cols)\n",
        "\n",
        "        image = apply_mask(image, mask, color)\n",
        "\n",
        "        contour_frame = np.zeros((height,width), dtype=np.uint8)\n",
        "        contour_frame = apply_mask2(contour_frame, mask, num=255)\n",
        "        ret, thr = cv2.threshold(contour_frame, 127, 255, 0)\n",
        "        contours, _ = cv2.findContours(thr, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
        "        \n",
        "        \n",
        "        if frame_acc >= 0.9 and label_index != 1:\n",
        "          isEmergency = 1\n",
        "\n",
        "        if (label_index != 1) :\n",
        "          caption = 'EMergency! {} {:.2f}'.format(label, score) if score else label\n",
        "          #image = cv2.rectangle(image, (x1, y1), (x2, y2), red, 2)\n",
        "          if isEmergency == 1:\n",
        "            emergencyImage = image[y1:y2, x1:x2, :]\n",
        "            cv2.drawContours(image, contours, -1, (0,0,255), 1)\n",
        "          else :\n",
        "            cv2.drawContours(image, contours, -1, (0,255,255), 1)\n",
        "        else :\n",
        "          cv2.drawContours(image, contours, -1, (0,255,0), 1)\n",
        "          #image = cv2.rectangle(image, (x1, y1), (x2, y2), color, 2)\n",
        "        image = cv2.putText(\n",
        "            image, caption, (x1, y1), cv2.FONT_HERSHEY_COMPLEX, 0.7, color, 2\n",
        "        )\n",
        "\n",
        "\n",
        "    print(np.max(weight_frame))\n",
        "    weight_frame[weight_frame>=1] -= 1\n",
        "    global logo\n",
        "    if isEmergency == 1:\n",
        "      image = img_overlay(image, logo, image.shape[0], 0, 0)\n",
        "\n",
        "    return image, emergencyImage, isEmergency\n",
        "\n",
        "capture = cv2.VideoCapture(1)\n",
        "\n",
        "(grabbed, frame) = capture.read()\n",
        "image_h = frame.shape[0]\n",
        "image_w = frame.shape[1]\n",
        "weight_frame = np.zeros((image_h,image_w), dtype=np.uint8)\n",
        "_lock = threading.Lock() # 쓰레딩 시 사용되는 lock\n",
        "\n",
        "frame_for_crop = None # 응급 상황 크롭 이미지 변수\n",
        "emer_for_bool = 0 # 응급상황 여부 변수. 0이면 정상, 1이면 응급 상황\n",
        "frame_for_screen = None # 현재 영상 이미지 변수\n",
        "\n",
        "app = Flask(__name__)\n",
        "\n",
        "@app.route(\"/\")\n",
        "def main():\n",
        "  return render_template('index.html')\n",
        "\n",
        "# 영상 프레임 처리 후 결과 반환 쓰레드\n",
        "def webcam(capture):\n",
        "  global frame_for_screen, _lock, emer_for_bool, frame_for_crop\n",
        "\n",
        "  while True:\n",
        "\n",
        "    grabbed, frame = capture.read()\n",
        "    if not grabbed:\n",
        "      print (\"Not grabbed.\")\n",
        "    \n",
        "    results = model.detect([frame], verbose=1)\n",
        "    \n",
        "    # Visualize results\n",
        "    r = results[0]\n",
        "    masked_frame , masked_list, isEmergency = display_instances(frame, r['rois'], r['masks'], r['class_ids'],\n",
        "                              class_names, r['scores'])\n",
        "    \n",
        "    with _lock:\n",
        "      frame_for_screen = masked_frame.copy()\n",
        "      frame_for_crop = masked_list.copy()\n",
        "      emer_for_bool = isEmergency\n",
        "\n",
        "# 현재 영상의 프레임을 스크린에 띄워주는 제너레이터\n",
        "def generate():\n",
        "\n",
        "    global frame_for_screen, _lock\n",
        "\n",
        "    while True:\n",
        "      with _lock:\n",
        "        if frame_for_screen is None:\n",
        "          continue\n",
        "        \n",
        "        encode_param=[int(cv2.IMWRITE_JPEG_QUALITY), 90]\n",
        "        (flag, encodedImage) = cv2.imencode(\".jpg\", frame_for_screen, encode_param)\n",
        "        if not flag:\n",
        "          continue\n",
        "      \n",
        "      yield (b'--frame\\r\\n' b'Content-Type: image/jpeg\\r\\n\\r\\n' + bytearray(encodedImage) + b'\\r\\n')\n",
        "\n",
        "\n",
        "@app.route(\"/video_feed\")\n",
        "def video_feed():\n",
        "  return Response(generate(), mimetype = \"multipart/x-mixed-replace; boundary=frame\")\n",
        "\n",
        "\n",
        "# 응급상황의 크롭 이미지를 띄워주는 제너레이터\n",
        "def emergency():\n",
        "  global emer_for_bool, frame_for_crop\n",
        "  count = 0\n",
        "  while True:\n",
        "    with _lock:\n",
        "      if emer_for_bool==1 and (count==0 or count==1):\n",
        "        encode_param=[int(cv2.IMWRITE_JPEG_QUALITY), 90]\n",
        "        flag, encodedImage = cv2.imencode(\".jpg\", frame_for_crop, encode_param)\n",
        "        yield (b'--frame\\r\\n' b'Content-Type: image/jpeg\\r\\n\\r\\n' + bytearray(encodedImage) + b'\\r\\n')\n",
        "        count+=1\n",
        "        continue\n",
        "      elif emer_for_bool==1 and count==1:\n",
        "        count=2\n",
        "      elif emer_for_bool==0:\n",
        "        count=0\n",
        "  \n",
        "\n",
        "@app.route(\"/isEmg\")\n",
        "def isEmg():\n",
        "  return Response(emergency(), mimetype = \"multipart/x-mixed-replace; boundary=frame\")\n",
        "print('server start')\n",
        "\n",
        "# 응급상황의 여부를 로그로 알려주는 제너레이터\n",
        "def log_gen():\n",
        "  global emer_for_bool\n",
        "\n",
        "  if emer_for_bool==1:\n",
        "    emer_for_text = \"emergency\"\n",
        "    yield emer_for_text\n",
        "  else :\n",
        "    emer_for_text = \"normal\"\n",
        "    yield emer_for_text\n",
        "    \n",
        "@app.route(\"/for_log\")\n",
        "def for_log():\n",
        "  return Response(log_gen())\n",
        "\n",
        "# 경고상황의 여부를 로그로 알려주는 제너레이터\n",
        "def log_gen_warn():\n",
        "  global emer_for_bool, weight_frame\n",
        "\n",
        "  if (emer_for_bool==0) and (np.max(weight_frame)== MAXIMUM_WEIGHT):\n",
        "    emer_for_text = \"warning\"\n",
        "    yield emer_for_text\n",
        "    \n",
        "@app.route(\"/for_warn_log\")\n",
        "def for_warn_log():\n",
        "  return Response(log_gen_warn())\n",
        "\n",
        "def log_gen_weight():\n",
        "  global MAXIMUM_WEIGHT\n",
        "  yield MAXIMUM_WEIGHT\n",
        "  \n",
        "@app.route(\"/for_warn_weight\")\n",
        "def for_warn_weight():\n",
        "  return Response(log_gen_weight())\n",
        "\n",
        "args = sys.argv\n",
        "if(len(args) <2):\n",
        "  print(\"run command: python or video: file name\")\n",
        "  sys.exit(0) \n",
        "name = args[1]\n",
        "if(len(args[1]) == 0):\n",
        "  name = int(args[1])\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "# 쓰레딩 시작  \n",
        "  threading.Thread(target=app.run).start()\n",
        "  threading.Thread(target=webcam(capture)).start()  "
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From C:\\Users\\JeongBeomJin\\Anaconda3\\envs\\OpenCV\\lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n",
            "WARNING:tensorflow:From C:\\Users\\JeongBeomJin\\Anaconda3\\envs\\OpenCV\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "\n",
            "Configurations:\n",
            "BACKBONE                       resnet101\n",
            "BACKBONE_STRIDES               [4, 8, 16, 32, 64]\n",
            "BATCH_SIZE                     1\n",
            "BBOX_STD_DEV                   [0.1 0.1 0.2 0.2]\n",
            "COMPUTE_BACKBONE_SHAPE         None\n",
            "DETECTION_MAX_INSTANCES        100\n",
            "DETECTION_MIN_CONFIDENCE       0.7\n",
            "DETECTION_NMS_THRESHOLD        0.3\n",
            "FPN_CLASSIF_FC_LAYERS_SIZE     1024\n",
            "GPU_COUNT                      1\n",
            "GRADIENT_CLIP_NORM             5.0\n",
            "IMAGES_PER_GPU                 1\n",
            "IMAGE_CHANNEL_COUNT            3\n",
            "IMAGE_MAX_DIM                  1024\n",
            "IMAGE_META_SIZE                93\n",
            "IMAGE_MIN_DIM                  800\n",
            "IMAGE_MIN_SCALE                0\n",
            "IMAGE_RESIZE_MODE              square\n",
            "IMAGE_SHAPE                    [1024 1024    3]\n",
            "LEARNING_MOMENTUM              0.9\n",
            "LEARNING_RATE                  0.001\n",
            "LOSS_WEIGHTS                   {'rpn_class_loss': 1.0, 'rpn_bbox_loss': 1.0, 'mrcnn_class_loss': 1.0, 'mrcnn_bbox_loss': 1.0, 'mrcnn_mask_loss': 1.0}\n",
            "MASK_POOL_SIZE                 14\n",
            "MASK_SHAPE                     [28, 28]\n",
            "MAX_GT_INSTANCES               100\n",
            "MEAN_PIXEL                     [123.7 116.8 103.9]\n",
            "MINI_MASK_SHAPE                (56, 56)\n",
            "NAME                           coco\n",
            "NUM_CLASSES                    81\n",
            "POOL_SIZE                      7\n",
            "POST_NMS_ROIS_INFERENCE        1000\n",
            "POST_NMS_ROIS_TRAINING         2000\n",
            "PRE_NMS_LIMIT                  6000\n",
            "ROI_POSITIVE_RATIO             0.33\n",
            "RPN_ANCHOR_RATIOS              [0.5, 1, 2]\n",
            "RPN_ANCHOR_SCALES              (32, 64, 128, 256, 512)\n",
            "RPN_ANCHOR_STRIDE              1\n",
            "RPN_BBOX_STD_DEV               [0.1 0.1 0.2 0.2]\n",
            "RPN_NMS_THRESHOLD              0.7\n",
            "RPN_TRAIN_ANCHORS_PER_IMAGE    256\n",
            "STEPS_PER_EPOCH                1000\n",
            "TOP_DOWN_PYRAMID_SIZE          256\n",
            "TRAIN_BN                       False\n",
            "TRAIN_ROIS_PER_IMAGE           200\n",
            "USE_MINI_MASK                  True\n",
            "USE_RPN_ROIS                   True\n",
            "VALIDATION_STEPS               50\n",
            "WEIGHT_DECAY                   0.0001\n",
            "\n",
            "\n",
            "WARNING:tensorflow:From C:\\MRCNN_pure_02\\mrcnn\\model.py:772: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "server start\n",
            " * Serving Flask app \"__main__\" (lazy loading)\n",
            " * Environment: production\n",
            "   WARNING: This is a development server. Do not use it in a production deployment.\n",
            "   Use a production WSGI server instead.\n",
            " * Debug mode: off\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " * Running on http://127.0.0.1:5000/ (Press CTRL+C to quit)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Processing 1 images\n",
            "image                    shape: (480, 640, 3)         min:    0.00000  max:  255.00000  uint8\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "127.0.0.1 - - [26/Nov/2020 16:33:20] \"\u001b[37mGET /for_log HTTP/1.1\u001b[0m\" 200 -\n",
            "127.0.0.1 - - [26/Nov/2020 16:33:20] \"\u001b[37mGET /for_log HTTP/1.1\u001b[0m\" 200 -\n",
            "127.0.0.1 - - [26/Nov/2020 16:33:20] \"\u001b[37mGET /for_log HTTP/1.1\u001b[0m\" 200 -\n",
            "127.0.0.1 - - [26/Nov/2020 16:33:20] \"\u001b[37mGET /for_log HTTP/1.1\u001b[0m\" 200 -\n",
            "127.0.0.1 - - [26/Nov/2020 16:33:20] \"\u001b[37mGET /for_log HTTP/1.1\u001b[0m\" 200 -\n",
            "127.0.0.1 - - [26/Nov/2020 16:33:20] \"\u001b[37mGET /for_log HTTP/1.1\u001b[0m\" 200 -\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "molded_images            shape: (1, 1024, 1024, 3)    min: -123.70000  max:  151.10000  float64\n",
            "image_metas              shape: (1, 93)               min:    0.00000  max: 1024.00000  float64\n",
            "anchors                  shape: (1, 261888, 4)        min:   -0.35390  max:    1.29134  float32\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "127.0.0.1 - - [26/Nov/2020 16:33:21] \"\u001b[37mGET /for_log HTTP/1.1\u001b[0m\" 200 -\n",
            "127.0.0.1 - - [26/Nov/2020 16:33:21] \"\u001b[37mGET / HTTP/1.1\u001b[0m\" 200 -\n",
            "127.0.0.1 - - [26/Nov/2020 16:33:22] \"\u001b[37mGET /for_log HTTP/1.1\u001b[0m\" 200 -\n",
            "127.0.0.1 - - [26/Nov/2020 16:33:23] \"\u001b[37mGET /for_log HTTP/1.1\u001b[0m\" 200 -\n",
            "127.0.0.1 - - [26/Nov/2020 16:33:23] \"\u001b[37mGET /for_log HTTP/1.1\u001b[0m\" 200 -\n",
            "127.0.0.1 - - [26/Nov/2020 16:33:24] \"\u001b[37mGET /for_log HTTP/1.1\u001b[0m\" 200 -\n",
            "127.0.0.1 - - [26/Nov/2020 16:33:24] \"\u001b[37mGET /for_log HTTP/1.1\u001b[0m\" 200 -\n",
            "127.0.0.1 - - [26/Nov/2020 16:33:25] \"\u001b[37mGET /for_log HTTP/1.1\u001b[0m\" 200 -\n",
            "127.0.0.1 - - [26/Nov/2020 16:33:25] \"\u001b[37mGET /for_log HTTP/1.1\u001b[0m\" 200 -\n",
            "127.0.0.1 - - [26/Nov/2020 16:33:26] \"\u001b[37mGET /for_log HTTP/1.1\u001b[0m\" 200 -\n",
            "127.0.0.1 - - [26/Nov/2020 16:33:26] \"\u001b[37mGET /for_log HTTP/1.1\u001b[0m\" 200 -\n",
            "127.0.0.1 - - [26/Nov/2020 16:33:27] \"\u001b[37mGET /for_log HTTP/1.1\u001b[0m\" 200 -\n",
            "127.0.0.1 - - [26/Nov/2020 16:33:27] \"\u001b[37mGET /for_log HTTP/1.1\u001b[0m\" 200 -\n",
            "127.0.0.1 - - [26/Nov/2020 16:33:28] \"\u001b[37mGET /for_log HTTP/1.1\u001b[0m\" 200 -\n",
            "127.0.0.1 - - [26/Nov/2020 16:33:28] \"\u001b[37mGET /for_log HTTP/1.1\u001b[0m\" 200 -\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "test27\n",
            "Current frame pixels :  78387\n",
            "Same pixels:  0\n",
            "Frame acc:  0.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "127.0.0.1 - - [26/Nov/2020 16:33:29] \"\u001b[37mGET /for_log HTTP/1.1\u001b[0m\" 200 -\n",
            "127.0.0.1 - - [26/Nov/2020 16:33:29] \"\u001b[37mGET /for_log HTTP/1.1\u001b[0m\" 200 -\n",
            "127.0.0.1 - - [26/Nov/2020 16:33:29] \"\u001b[37mGET /for_warn_log HTTP/1.1\u001b[0m\" 200 -\n",
            "127.0.0.1 - - [26/Nov/2020 16:33:29] \"\u001b[37mGET /video_feed HTTP/1.1\u001b[0m\" 200 -\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[] []\n",
            "2\n",
            "Processing 1 images\n",
            "image                    shape: (480, 640, 3)         min:    0.00000  max:  255.00000  uint8\n",
            "molded_images            shape: (1, 1024, 1024, 3)    min: -123.70000  max:  151.10000  float64\n",
            "image_metas              shape: (1, 93)               min:    0.00000  max: 1024.00000  float64\n",
            "anchors                  shape: (1, 261888, 4)        min:   -0.35390  max:    1.29134  float32\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "127.0.0.1 - - [26/Nov/2020 16:33:30] \"\u001b[37mGET /for_log HTTP/1.1\u001b[0m\" 200 -\n",
            "127.0.0.1 - - [26/Nov/2020 16:33:30] \"\u001b[37mGET /for_log HTTP/1.1\u001b[0m\" 200 -\n",
            "127.0.0.1 - - [26/Nov/2020 16:33:31] \"\u001b[37mGET /for_log HTTP/1.1\u001b[0m\" 200 -\n",
            "127.0.0.1 - - [26/Nov/2020 16:33:31] \"\u001b[37mGET /for_log HTTP/1.1\u001b[0m\" 200 -\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "test27\n",
            "Current frame pixels :  60379\n",
            "Same pixels:  0\n",
            "Frame acc:  0.0\n",
            "[] []\n",
            "3\n",
            "Processing 1 images\n",
            "image                    shape: (480, 640, 3)         min:    0.00000  max:  255.00000  uint8\n",
            "molded_images            shape: (1, 1024, 1024, 3)    min: -123.70000  max:  151.10000  float64\n",
            "image_metas              shape: (1, 93)               min:    0.00000  max: 1024.00000  float64\n",
            "anchors                  shape: (1, 261888, 4)        min:   -0.35390  max:    1.29134  float32\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "127.0.0.1 - - [26/Nov/2020 16:33:32] \"\u001b[37mGET /for_log HTTP/1.1\u001b[0m\" 200 -\n",
            "127.0.0.1 - - [26/Nov/2020 16:33:32] \"\u001b[37mGET /for_warn_log HTTP/1.1\u001b[0m\" 200 -\n",
            "127.0.0.1 - - [26/Nov/2020 16:33:32] \"\u001b[37mGET /for_log HTTP/1.1\u001b[0m\" 200 -\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "test27\n",
            "Current frame pixels :  41633\n",
            "Same pixels:  0\n",
            "Frame acc:  0.0\n",
            "[] []\n",
            "test27\n",
            "Current frame pixels :  138005\n",
            "Same pixels:  0\n",
            "Frame acc:  0.0\n",
            "[] []\n",
            "6\n",
            "Processing 1 images\n",
            "image                    shape: (480, 640, 3)         min:    0.00000  max:  255.00000  uint8\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "127.0.0.1 - - [26/Nov/2020 16:33:33] \"\u001b[37mGET /for_log HTTP/1.1\u001b[0m\" 200 -\n",
            "127.0.0.1 - - [26/Nov/2020 16:33:33] \"\u001b[37mGET /for_log HTTP/1.1\u001b[0m\" 200 -\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "molded_images            shape: (1, 1024, 1024, 3)    min: -123.70000  max:  151.10000  float64\n",
            "image_metas              shape: (1, 93)               min:    0.00000  max: 1024.00000  float64\n",
            "anchors                  shape: (1, 261888, 4)        min:   -0.35390  max:    1.29134  float32\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "127.0.0.1 - - [26/Nov/2020 16:33:34] \"\u001b[37mGET /for_log HTTP/1.1\u001b[0m\" 200 -\n",
            "127.0.0.1 - - [26/Nov/2020 16:33:34] \"\u001b[37mGET /for_log HTTP/1.1\u001b[0m\" 200 -\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "test27\n",
            "Current frame pixels :  49411\n",
            "Same pixels:  0\n",
            "Frame acc:  0.0\n",
            "[] []\n",
            "7\n",
            "Processing 1 images\n",
            "image                    shape: (480, 640, 3)         min:    0.00000  max:  255.00000  uint8\n",
            "molded_images            shape: (1, 1024, 1024, 3)    min: -123.70000  max:  151.10000  float64\n",
            "image_metas              shape: (1, 93)               min:    0.00000  max: 1024.00000  float64\n",
            "anchors                  shape: (1, 261888, 4)        min:   -0.35390  max:    1.29134  float32\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "127.0.0.1 - - [26/Nov/2020 16:33:35] \"\u001b[37mGET /for_log HTTP/1.1\u001b[0m\" 200 -\n",
            "127.0.0.1 - - [26/Nov/2020 16:33:35] \"\u001b[37mGET /for_log HTTP/1.1\u001b[0m\" 200 -\n",
            "127.0.0.1 - - [26/Nov/2020 16:33:36] \"\u001b[37mGET /for_log HTTP/1.1\u001b[0m\" 200 -\n",
            "127.0.0.1 - - [26/Nov/2020 16:33:36] \"\u001b[37mGET /for_log HTTP/1.1\u001b[0m\" 200 -\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "test27\n",
            "Current frame pixels :  51370\n",
            "Same pixels:  0\n",
            "Frame acc:  0.0\n",
            "[] []\n",
            "8\n",
            "Processing 1 images\n",
            "image                    shape: (480, 640, 3)         min:    0.00000  max:  255.00000  uint8\n",
            "molded_images            shape: (1, 1024, 1024, 3)    min: -123.70000  max:  151.10000  float64\n",
            "image_metas              shape: (1, 93)               min:    0.00000  max: 1024.00000  float64\n",
            "anchors                  shape: (1, 261888, 4)        min:   -0.35390  max:    1.29134  float32\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "127.0.0.1 - - [26/Nov/2020 16:33:37] \"\u001b[37mGET /for_log HTTP/1.1\u001b[0m\" 200 -\n",
            "127.0.0.1 - - [26/Nov/2020 16:33:37] \"\u001b[37mGET /for_log HTTP/1.1\u001b[0m\" 200 -\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "test27\n",
            "Current frame pixels :  38679\n",
            "Same pixels:  0\n",
            "Frame acc:  0.0\n",
            "[] []\n",
            "test27\n",
            "Current frame pixels :  119815\n",
            "Same pixels:  10813\n",
            "Frame acc:  0.09024746484163085\n",
            "[242 243 243 ... 463 463 463] [362 361 362 ... 339 340 341]\n",
            "test27\n",
            "Current frame pixels :  33935\n",
            "Same pixels:  1559\n",
            "Frame acc:  0.045940769117430384\n",
            "[242 243 243 ... 463 463 463] [362 361 362 ... 339 340 341]\n",
            "10\n",
            "Processing 1 images\n",
            "image                    shape: (480, 640, 3)         min:    0.00000  max:  255.00000  uint8\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "127.0.0.1 - - [26/Nov/2020 16:33:38] \"\u001b[37mGET /for_log HTTP/1.1\u001b[0m\" 200 -\n",
            "127.0.0.1 - - [26/Nov/2020 16:33:38] \"\u001b[37mGET /for_log HTTP/1.1\u001b[0m\" 200 -\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "molded_images            shape: (1, 1024, 1024, 3)    min: -123.70000  max:  151.10000  float64\n",
            "image_metas              shape: (1, 93)               min:    0.00000  max: 1024.00000  float64\n",
            "anchors                  shape: (1, 261888, 4)        min:   -0.35390  max:    1.29134  float32\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "127.0.0.1 - - [26/Nov/2020 16:33:39] \"\u001b[37mGET /for_log HTTP/1.1\u001b[0m\" 200 -\n",
            "127.0.0.1 - - [26/Nov/2020 16:33:39] \"\u001b[37mGET /for_log HTTP/1.1\u001b[0m\" 200 -\n",
            "127.0.0.1 - - [26/Nov/2020 16:33:39] \"\u001b[37mGET /for_warn_log HTTP/1.1\u001b[0m\" 200 -\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "test27\n",
            "Current frame pixels :  38580\n",
            "Same pixels:  20463\n",
            "Frame acc:  0.5304043545878694\n",
            "[239 240 240 ... 465 465 465] [361 361 362 ... 474 475 476]\n",
            "test27\n",
            "Current frame pixels :  110959\n",
            "Same pixels:  14674\n",
            "Frame acc:  0.13224704620625635\n",
            "[216 216 216 ... 465 465 465] [345 346 347 ... 474 475 476]\n",
            "10\n",
            "Processing 1 images\n",
            "image                    shape: (480, 640, 3)         min:    0.00000  max:  255.00000  uint8\n",
            "molded_images            shape: (1, 1024, 1024, 3)    min: -123.70000  max:  151.10000  float64\n",
            "image_metas              shape: (1, 93)               min:    0.00000  max: 1024.00000  float64\n",
            "anchors                  shape: (1, 261888, 4)        min:   -0.35390  max:    1.29134  float32\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "127.0.0.1 - - [26/Nov/2020 16:33:40] \"\u001b[37mGET /for_log HTTP/1.1\u001b[0m\" 200 -\n",
            "127.0.0.1 - - [26/Nov/2020 16:33:40] \"\u001b[37mGET /for_log HTTP/1.1\u001b[0m\" 200 -\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "test27\n",
            "Current frame pixels :  38921\n",
            "Same pixels:  20846\n",
            "Frame acc:  0.5355977492870173\n",
            "[239 240 240 ... 465 465 465] [361 361 362 ... 474 475 476]\n",
            "test27\n",
            "Current frame pixels :  115774\n",
            "Same pixels:  16640\n",
            "Frame acc:  0.14372829823621883\n",
            "[216 216 216 ... 465 465 465] [345 346 347 ... 474 475 476]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "127.0.0.1 - - [26/Nov/2020 16:33:41] \"\u001b[37mGET /for_log HTTP/1.1\u001b[0m\" 200 -\n",
            "127.0.0.1 - - [26/Nov/2020 16:33:41] \"\u001b[37mGET /for_log HTTP/1.1\u001b[0m\" 200 -\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "10\n",
            "Processing 1 images\n",
            "image                    shape: (480, 640, 3)         min:    0.00000  max:  255.00000  uint8\n",
            "molded_images            shape: (1, 1024, 1024, 3)    min: -123.70000  max:  151.10000  float64\n",
            "image_metas              shape: (1, 93)               min:    0.00000  max: 1024.00000  float64\n",
            "anchors                  shape: (1, 261888, 4)        min:   -0.35390  max:    1.29134  float32\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "127.0.0.1 - - [26/Nov/2020 16:33:42] \"\u001b[37mGET /for_log HTTP/1.1\u001b[0m\" 200 -\n",
            "127.0.0.1 - - [26/Nov/2020 16:33:42] \"\u001b[37mGET /for_warn_log HTTP/1.1\u001b[0m\" 200 -\n",
            "127.0.0.1 - - [26/Nov/2020 16:33:42] \"\u001b[37mGET /for_log HTTP/1.1\u001b[0m\" 200 -\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "test27\n",
            "Current frame pixels :  52055\n",
            "Same pixels:  21539\n",
            "Frame acc:  0.41377389299779077\n",
            "[318 319 320 ... 468 468 468] [317 317 316 ... 470 471 472]\n",
            "10\n",
            "Processing 1 images\n",
            "image                    shape: (480, 640, 3)         min:    0.00000  max:  255.00000  uint8\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "127.0.0.1 - - [26/Nov/2020 16:33:43] \"\u001b[37mGET /for_log HTTP/1.1\u001b[0m\" 200 -\n",
            "127.0.0.1 - - [26/Nov/2020 16:33:43] \"\u001b[37mGET /for_log HTTP/1.1\u001b[0m\" 200 -\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "molded_images            shape: (1, 1024, 1024, 3)    min: -123.70000  max:  151.10000  float64\n",
            "image_metas              shape: (1, 93)               min:    0.00000  max: 1024.00000  float64\n",
            "anchors                  shape: (1, 261888, 4)        min:   -0.35390  max:    1.29134  float32\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "127.0.0.1 - - [26/Nov/2020 16:33:44] \"\u001b[37mGET /for_log HTTP/1.1\u001b[0m\" 200 -\n",
            "127.0.0.1 - - [26/Nov/2020 16:33:44] \"\u001b[37mGET /for_log HTTP/1.1\u001b[0m\" 200 -\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "test27\n",
            "Current frame pixels :  65754\n",
            "Same pixels:  20744\n",
            "Frame acc:  0.3154789062262372\n",
            "[360 360 360 ... 468 468 468] [299 300 301 ... 443 444 445]\n",
            "10\n",
            "Processing 1 images\n",
            "image                    shape: (480, 640, 3)         min:    0.00000  max:  255.00000  uint8\n",
            "molded_images            shape: (1, 1024, 1024, 3)    min: -123.70000  max:  151.10000  float64\n",
            "image_metas              shape: (1, 93)               min:    0.00000  max: 1024.00000  float64\n",
            "anchors                  shape: (1, 261888, 4)        min:   -0.35390  max:    1.29134  float32\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "127.0.0.1 - - [26/Nov/2020 16:33:45] \"\u001b[37mGET /for_log HTTP/1.1\u001b[0m\" 200 -\n",
            "127.0.0.1 - - [26/Nov/2020 16:33:45] \"\u001b[37mGET /for_log HTTP/1.1\u001b[0m\" 200 -\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "test27\n",
            "Current frame pixels :  67458\n",
            "Same pixels:  23359\n",
            "Frame acc:  0.3462747190844674\n",
            "[260 260 261 ... 469 469 469] [192 193 192 ... 438 439 440]\n",
            "10\n",
            "Processing 1 images\n",
            "image                    shape: (480, 640, 3)         min:    0.00000  max:  255.00000  uint8\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "127.0.0.1 - - [26/Nov/2020 16:33:46] \"\u001b[37mGET /for_log HTTP/1.1\u001b[0m\" 200 -\n",
            "127.0.0.1 - - [26/Nov/2020 16:33:46] \"\u001b[37mGET /for_log HTTP/1.1\u001b[0m\" 200 -\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "molded_images            shape: (1, 1024, 1024, 3)    min: -123.70000  max:  151.10000  float64\n",
            "image_metas              shape: (1, 93)               min:    0.00000  max: 1024.00000  float64\n",
            "anchors                  shape: (1, 261888, 4)        min:   -0.35390  max:    1.29134  float32\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "127.0.0.1 - - [26/Nov/2020 16:33:47] \"\u001b[37mGET /for_log HTTP/1.1\u001b[0m\" 200 -\n",
            "127.0.0.1 - - [26/Nov/2020 16:33:47] \"\u001b[37mGET /for_log HTTP/1.1\u001b[0m\" 200 -\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "test27\n",
            "Current frame pixels :  63510\n",
            "Same pixels:  27357\n",
            "Frame acc:  0.430751062824752\n",
            "[240 241 242 ... 468 468 468] [137 136 136 ... 431 432 433]\n",
            "10\n",
            "Processing 1 images\n",
            "image                    shape: (480, 640, 3)         min:    0.00000  max:  255.00000  uint8\n",
            "molded_images            shape: (1, 1024, 1024, 3)    min: -123.70000  max:  151.10000  float64\n",
            "image_metas              shape: (1, 93)               min:    0.00000  max: 1024.00000  float64\n",
            "anchors                  shape: (1, 261888, 4)        min:   -0.35390  max:    1.29134  float32\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "127.0.0.1 - - [26/Nov/2020 16:33:48] \"\u001b[37mGET /for_log HTTP/1.1\u001b[0m\" 200 -\n",
            "127.0.0.1 - - [26/Nov/2020 16:33:48] \"\u001b[37mGET /for_log HTTP/1.1\u001b[0m\" 200 -\n",
            "127.0.0.1 - - [26/Nov/2020 16:33:49] \"\u001b[37mGET /for_log HTTP/1.1\u001b[0m\" 200 -\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "test27\n",
            "Current frame pixels :  62775\n",
            "Same pixels:  30742\n",
            "Frame acc:  0.4897172441258463\n",
            "[232 233 234 ... 467 467 467] [193 193 192 ... 429 430 431]\n",
            "test27\n",
            "Current frame pixels :  38197\n",
            "Same pixels:  0\n",
            "Frame acc:  0.0\n",
            "[232 233 234 ... 467 467 467] [193 193 192 ... 429 430 431]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "127.0.0.1 - - [26/Nov/2020 16:33:49] \"\u001b[37mGET /for_log HTTP/1.1\u001b[0m\" 200 -\n",
            "127.0.0.1 - - [26/Nov/2020 16:33:49] \"\u001b[37mGET /for_warn_log HTTP/1.1\u001b[0m\" 200 -\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "10\n",
            "Processing 1 images\n",
            "image                    shape: (480, 640, 3)         min:    0.00000  max:  255.00000  uint8\n",
            "molded_images            shape: (1, 1024, 1024, 3)    min: -123.70000  max:  151.10000  float64\n",
            "image_metas              shape: (1, 93)               min:    0.00000  max: 1024.00000  float64\n",
            "anchors                  shape: (1, 261888, 4)        min:   -0.35390  max:    1.29134  float32\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "127.0.0.1 - - [26/Nov/2020 16:33:50] \"\u001b[37mGET /for_log HTTP/1.1\u001b[0m\" 200 -\n",
            "127.0.0.1 - - [26/Nov/2020 16:33:50] \"\u001b[37mGET /for_log HTTP/1.1\u001b[0m\" 200 -\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "test27\n",
            "Current frame pixels :  65745\n",
            "Same pixels:  38606\n",
            "Frame acc:  0.5872081527112328\n",
            "[216 216 217 ... 468 468 468] [186 187 182 ... 431 432 433]\n",
            "10\n",
            "Processing 1 images\n",
            "image                    shape: (480, 640, 3)         min:    0.00000  max:  255.00000  uint8\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "127.0.0.1 - - [26/Nov/2020 16:33:51] \"\u001b[37mGET /for_log HTTP/1.1\u001b[0m\" 200 -\n",
            "127.0.0.1 - - [26/Nov/2020 16:33:51] \"\u001b[37mGET /for_log HTTP/1.1\u001b[0m\" 200 -\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "molded_images            shape: (1, 1024, 1024, 3)    min: -123.70000  max:  151.10000  float64\n",
            "image_metas              shape: (1, 93)               min:    0.00000  max: 1024.00000  float64\n",
            "anchors                  shape: (1, 261888, 4)        min:   -0.35390  max:    1.29134  float32\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "127.0.0.1 - - [26/Nov/2020 16:33:52] \"\u001b[37mGET /for_log HTTP/1.1\u001b[0m\" 200 -\n",
            "127.0.0.1 - - [26/Nov/2020 16:33:52] \"\u001b[37mGET /for_warn_log HTTP/1.1\u001b[0m\" 200 -\n",
            "127.0.0.1 - - [26/Nov/2020 16:33:52] \"\u001b[37mGET /for_log HTTP/1.1\u001b[0m\" 200 -\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "test27\n",
            "Current frame pixels :  64970\n",
            "Same pixels:  39641\n",
            "Frame acc:  0.6101431429890719\n",
            "[216 216 217 ... 469 469 469] [186 187 182 ... 423 424 425]\n",
            "test27\n",
            "Current frame pixels :  30967\n",
            "Same pixels:  0\n",
            "Frame acc:  0.0\n",
            "[216 216 217 ... 469 469 469] [186 187 182 ... 423 424 425]\n",
            "10\n",
            "Processing 1 images\n",
            "image                    shape: (480, 640, 3)         min:    0.00000  max:  255.00000  uint8\n",
            "molded_images            shape: (1, 1024, 1024, 3)    min: -123.70000  max:  151.10000  float64\n",
            "image_metas              shape: (1, 93)               min:    0.00000  max: 1024.00000  float64\n",
            "anchors                  shape: (1, 261888, 4)        min:   -0.35390  max:    1.29134  float32\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "127.0.0.1 - - [26/Nov/2020 16:33:53] \"\u001b[37mGET /for_log HTTP/1.1\u001b[0m\" 200 -\n",
            "127.0.0.1 - - [26/Nov/2020 16:33:53] \"\u001b[37mGET /for_log HTTP/1.1\u001b[0m\" 200 -\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "test27\n",
            "Current frame pixels :  65799\n",
            "Same pixels:  53048\n",
            "Frame acc:  0.8062128603778173\n",
            "[203 203 203 ... 469 469 469] [139 140 141 ... 423 424 425]\n",
            "10\n",
            "Processing 1 images\n",
            "image                    shape: (480, 640, 3)         min:    0.00000  max:  255.00000  uint8\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "127.0.0.1 - - [26/Nov/2020 16:33:54] \"\u001b[37mGET /for_log HTTP/1.1\u001b[0m\" 200 -\n",
            "127.0.0.1 - - [26/Nov/2020 16:33:54] \"\u001b[37mGET /for_log HTTP/1.1\u001b[0m\" 200 -\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "molded_images            shape: (1, 1024, 1024, 3)    min: -123.70000  max:  151.10000  float64\n",
            "image_metas              shape: (1, 93)               min:    0.00000  max: 1024.00000  float64\n",
            "anchors                  shape: (1, 261888, 4)        min:   -0.35390  max:    1.29134  float32\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "127.0.0.1 - - [26/Nov/2020 16:33:55] \"\u001b[37mGET /for_log HTTP/1.1\u001b[0m\" 200 -\n",
            "127.0.0.1 - - [26/Nov/2020 16:33:55] \"\u001b[37mGET /for_log HTTP/1.1\u001b[0m\" 200 -\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "test27\n",
            "Current frame pixels :  65467\n",
            "Same pixels:  55861\n",
            "Frame acc:  0.8532695862037363\n",
            "[203 203 203 ... 469 469 469] [139 140 141 ... 434 435 436]\n",
            "10\n",
            "Processing 1 images\n",
            "image                    shape: (480, 640, 3)         min:    0.00000  max:  255.00000  uint8\n",
            "molded_images            shape: (1, 1024, 1024, 3)    min: -123.70000  max:  151.10000  float64\n",
            "image_metas              shape: (1, 93)               min:    0.00000  max: 1024.00000  float64\n",
            "anchors                  shape: (1, 261888, 4)        min:   -0.35390  max:    1.29134  float32\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "127.0.0.1 - - [26/Nov/2020 16:33:56] \"\u001b[37mGET /for_log HTTP/1.1\u001b[0m\" 200 -\n",
            "127.0.0.1 - - [26/Nov/2020 16:33:56] \"\u001b[37mGET /for_log HTTP/1.1\u001b[0m\" 200 -\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "test27\n",
            "Current frame pixels :  66222\n",
            "Same pixels:  60408\n",
            "Frame acc:  0.9122044033704811\n",
            "[202 202 202 ... 469 469 469] [150 151 152 ... 434 435 436]\n",
            "test27\n",
            "Current frame pixels :  12095\n",
            "Same pixels:  0\n",
            "Frame acc:  0.0\n",
            "[202 202 202 ... 469 469 469] [150 151 152 ... 434 435 436]\n",
            "10"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "127.0.0.1 - - [26/Nov/2020 16:33:57] \"\u001b[37mGET /for_log HTTP/1.1\u001b[0m\" 200 -\n",
            "127.0.0.1 - - [26/Nov/2020 16:33:57] \"\u001b[37mGET /isEmg HTTP/1.1\u001b[0m\" 200 -\n",
            "127.0.0.1 - - [26/Nov/2020 16:33:57] \"\u001b[37mGET /for_log HTTP/1.1\u001b[0m\" 200 -\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Processing 1 images\n",
            "image                    shape: (480, 640, 3)         min:    0.00000  max:  255.00000  uint8\n",
            "molded_images            shape: (1, 1024, 1024, 3)    min: -123.70000  max:  151.10000  float64\n",
            "image_metas              shape: (1, 93)               min:    0.00000  max: 1024.00000  float64\n",
            "anchors                  shape: (1, 261888, 4)        min:   -0.35390  max:    1.29134  float32\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "127.0.0.1 - - [26/Nov/2020 16:33:58] \"\u001b[37mGET /for_log HTTP/1.1\u001b[0m\" 200 -\n",
            "127.0.0.1 - - [26/Nov/2020 16:33:58] \"\u001b[37mGET /for_log HTTP/1.1\u001b[0m\" 200 -\n",
            "127.0.0.1 - - [26/Nov/2020 16:33:58] \"\u001b[37mGET /static/bg2.png HTTP/1.1\u001b[0m\" 200 -\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "test27\n",
            "Current frame pixels :  66965\n",
            "Same pixels:  60677\n",
            "Frame acc:  0.9061002015978497\n",
            "[202 202 202 ... 470 470 470] [150 151 152 ... 407 408 409]\n",
            "test27\n",
            "Current frame pixels :  29043\n",
            "Same pixels:  0\n",
            "Frame acc:  0.0\n",
            "[202 202 202 ... 470 470 470] [150 151 152 ... 407 408 409]\n",
            "10\n",
            "Processing 1 images\n",
            "image                    shape: (480, 640, 3)         min:    0.00000  max:  255.00000  uint8\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "127.0.0.1 - - [26/Nov/2020 16:33:59] \"\u001b[37mGET /for_log HTTP/1.1\u001b[0m\" 200 -\n",
            "127.0.0.1 - - [26/Nov/2020 16:33:59] \"\u001b[37mGET /for_warn_log HTTP/1.1\u001b[0m\" 200 -\n",
            "127.0.0.1 - - [26/Nov/2020 16:33:59] \"\u001b[37mGET /for_log HTTP/1.1\u001b[0m\" 200 -\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "molded_images            shape: (1, 1024, 1024, 3)    min: -123.70000  max:  151.10000  float64\n",
            "image_metas              shape: (1, 93)               min:    0.00000  max: 1024.00000  float64\n",
            "anchors                  shape: (1, 261888, 4)        min:   -0.35390  max:    1.29134  float32\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "127.0.0.1 - - [26/Nov/2020 16:34:00] \"\u001b[37mGET /for_log HTTP/1.1\u001b[0m\" 200 -\n",
            "127.0.0.1 - - [26/Nov/2020 16:34:00] \"\u001b[37mGET /for_log HTTP/1.1\u001b[0m\" 200 -\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "test27\n",
            "Current frame pixels :  66942\n",
            "Same pixels:  61555\n",
            "Frame acc:  0.9195273520360909\n",
            "[201 201 201 ... 470 470 470] [157 158 159 ... 407 408 409]\n",
            "10\n",
            "Processing 1 images\n",
            "image                    shape: (480, 640, 3)         min:    0.00000  max:  255.00000  uint8\n",
            "molded_images            shape: (1, 1024, 1024, 3)    min: -123.70000  max:  151.10000  float64\n",
            "image_metas              shape: (1, 93)               min:    0.00000  max: 1024.00000  float64\n",
            "anchors                  shape: (1, 261888, 4)        min:   -0.35390  max:    1.29134  float32\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "127.0.0.1 - - [26/Nov/2020 16:34:01] \"\u001b[37mGET /for_log HTTP/1.1\u001b[0m\" 200 -\n",
            "127.0.0.1 - - [26/Nov/2020 16:34:01] \"\u001b[37mGET /for_log HTTP/1.1\u001b[0m\" 200 -\n",
            "127.0.0.1 - - [26/Nov/2020 16:34:02] \"\u001b[37mGET /for_log HTTP/1.1\u001b[0m\" 200 -\n",
            "127.0.0.1 - - [26/Nov/2020 16:34:02] \"\u001b[37mGET /for_warn_log HTTP/1.1\u001b[0m\" 200 -\n",
            "127.0.0.1 - - [26/Nov/2020 16:34:02] \"\u001b[37mGET /for_log HTTP/1.1\u001b[0m\" 200 -\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "test27\n",
            "Current frame pixels :  63725\n",
            "Same pixels:  58087\n",
            "Frame acc:  0.9115260886622205\n",
            "[201 201 201 ... 470 470 470] [157 158 159 ... 424 425 426]\n",
            "10\n",
            "Processing 1 images\n",
            "image                    shape: (480, 640, 3)         min:    0.00000  max:  255.00000  uint8\n",
            "molded_images            shape: (1, 1024, 1024, 3)    min: -123.70000  max:  151.10000  float64\n",
            "image_metas              shape: (1, 93)               min:    0.00000  max: 1024.00000  float64\n",
            "anchors                  shape: (1, 261888, 4)        min:   -0.35390  max:    1.29134  float32\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "127.0.0.1 - - [26/Nov/2020 16:34:03] \"\u001b[37mGET /for_log HTTP/1.1\u001b[0m\" 200 -\n",
            "127.0.0.1 - - [26/Nov/2020 16:34:03] \"\u001b[37mGET /for_log HTTP/1.1\u001b[0m\" 200 -\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "test27\n",
            "Current frame pixels :  71557\n",
            "Same pixels:  36101\n",
            "Frame acc:  0.5045068965999133\n",
            "[205 206 206 ... 470 470 470] [185 185 186 ... 424 425 426]\n",
            "10\n",
            "Processing 1 images\n",
            "image                    shape: (480, 640, 3)         min:    0.00000  max:  255.00000  uint8\n",
            "molded_images            shape: (1, 1024, 1024, 3)    min: -123.70000  max:  151.10000  float64\n",
            "image_metas              shape: (1, 93)               min:    0.00000  max: 1024.00000  float64\n",
            "anchors                  shape: (1, 261888, 4)        min:   -0.35390  max:    1.29134  float32\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "127.0.0.1 - - [26/Nov/2020 16:34:04] \"\u001b[37mGET /for_log HTTP/1.1\u001b[0m\" 200 -\n",
            "127.0.0.1 - - [26/Nov/2020 16:34:04] \"\u001b[37mGET /for_log HTTP/1.1\u001b[0m\" 200 -\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "test27\n",
            "Current frame pixels :  73928\n",
            "Same pixels:  39715\n",
            "Frame acc:  0.5372118818309707\n",
            "[214 215 215 ... 470 470 470] [199 199 200 ... 428 429 435]\n",
            "10\n",
            "Processing 1 images\n",
            "image                    shape: (480, 640, 3)         min:    0.00000  max:  255.00000  uint8\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "127.0.0.1 - - [26/Nov/2020 16:34:05] \"\u001b[37mGET /for_log HTTP/1.1\u001b[0m\" 200 -\n",
            "127.0.0.1 - - [26/Nov/2020 16:34:05] \"\u001b[37mGET /for_log HTTP/1.1\u001b[0m\" 200 -\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "molded_images            shape: (1, 1024, 1024, 3)    min: -123.70000  max:  151.10000  float64\n",
            "image_metas              shape: (1, 93)               min:    0.00000  max: 1024.00000  float64\n",
            "anchors                  shape: (1, 261888, 4)        min:   -0.35390  max:    1.29134  float32\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "127.0.0.1 - - [26/Nov/2020 16:34:06] \"\u001b[37mGET /for_log HTTP/1.1\u001b[0m\" 200 -\n",
            "127.0.0.1 - - [26/Nov/2020 16:34:06] \"\u001b[37mGET /for_log HTTP/1.1\u001b[0m\" 200 -\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "test27\n",
            "Current frame pixels :  73843\n",
            "Same pixels:  39326\n",
            "Frame acc:  0.5325623281827662\n",
            "[213 214 214 ... 470 470 470] [200 200 201 ... 428 429 435]\n",
            "10\n",
            "Processing 1 images\n",
            "image                    shape: (480, 640, 3)         min:    0.00000  max:  255.00000  uint8\n",
            "molded_images            shape: (1, 1024, 1024, 3)    min: -123.70000  max:  151.10000  float64\n",
            "image_metas              shape: (1, 93)               min:    0.00000  max: 1024.00000  float64\n",
            "anchors                  shape: (1, 261888, 4)        min:   -0.35390  max:    1.29134  float32\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "127.0.0.1 - - [26/Nov/2020 16:34:07] \"\u001b[37mGET /for_log HTTP/1.1\u001b[0m\" 200 -\n",
            "127.0.0.1 - - [26/Nov/2020 16:34:07] \"\u001b[37mGET /for_log HTTP/1.1\u001b[0m\" 200 -\n",
            "127.0.0.1 - - [26/Nov/2020 16:34:08] \"\u001b[37mGET /for_log HTTP/1.1\u001b[0m\" 200 -\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "test27\n",
            "Current frame pixels :  68287\n",
            "Same pixels:  35340\n",
            "Frame acc:  0.5175216366219046\n",
            "[213 213 214 ... 470 470 470] [200 201 199 ... 433 434 435]\n",
            "10\n",
            "Processing 1 images\n",
            "image                    shape: (480, 640, 3)         min:    0.00000  max:  255.00000  uint8\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "127.0.0.1 - - [26/Nov/2020 16:34:08] \"\u001b[37mGET /for_log HTTP/1.1\u001b[0m\" 200 -\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "molded_images            shape: (1, 1024, 1024, 3)    min: -123.70000  max:  151.10000  float64\n",
            "image_metas              shape: (1, 93)               min:    0.00000  max: 1024.00000  float64\n",
            "anchors                  shape: (1, 261888, 4)        min:   -0.35390  max:    1.29134  float32\n",
            "test27\n",
            "Current frame pixels :  64736\n",
            "Same pixels:  29721\n",
            "Frame acc:  0.4591108502224419\n",
            "[212 213 213 ... 470 470 470] [197 196 197 ... 433 434 435]\n",
            "10\n",
            "Processing 1 images\n",
            "image                    shape: (480, 640, 3)         min:    0.00000  max:  255.00000  uint8\n",
            "molded_images            shape: (1, 1024, 1024, 3)    min: -123.70000  max:  151.10000  float64\n",
            "image_metas              shape: (1, 93)               min:    0.00000  max: 1024.00000  float64\n",
            "anchors                  shape: (1, 261888, 4)        min:   -0.35390  max:    1.29134  float32\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "ERROR:root:Internal Python error in the inspect module.\n",
            "Below is the traceback from this internal error.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"C:\\Users\\JeongBeomJin\\Anaconda3\\envs\\OpenCV\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3331, in run_code\n",
            "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
            "  File \"<ipython-input-1-0648f3f8564c>\", line 388, in <module>\n",
            "    threading.Thread(target=webcam(capture)).start()\n",
            "  File \"<ipython-input-1-0648f3f8564c>\", line 283, in webcam\n",
            "    results = model.detect([frame], verbose=1)\n",
            "  File \"C:\\MRCNN_pure_02\\mrcnn\\model.py\", line 2524, in detect\n",
            "    self.keras_model.predict([molded_images, image_metas, anchors], verbose=0)\n",
            "  File \"C:\\Users\\JeongBeomJin\\Anaconda3\\envs\\OpenCV\\lib\\site-packages\\keras\\engine\\training.py\", line 1462, in predict\n",
            "    callbacks=callbacks)\n",
            "  File \"C:\\Users\\JeongBeomJin\\Anaconda3\\envs\\OpenCV\\lib\\site-packages\\keras\\engine\\training_arrays.py\", line 324, in predict_loop\n",
            "    batch_outs = f(ins_batch)\n",
            "  File \"C:\\Users\\JeongBeomJin\\Anaconda3\\envs\\OpenCV\\lib\\site-packages\\tensorflow\\python\\keras\\backend.py\", line 3076, in __call__\n",
            "    run_metadata=self.run_metadata)\n",
            "  File \"C:\\Users\\JeongBeomJin\\Anaconda3\\envs\\OpenCV\\lib\\site-packages\\tensorflow\\python\\client\\session.py\", line 1439, in __call__\n",
            "    run_metadata_ptr)\n",
            "KeyboardInterrupt\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"C:\\Users\\JeongBeomJin\\Anaconda3\\envs\\OpenCV\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2044, in showtraceback\n",
            "    stb = value._render_traceback_()\n",
            "AttributeError: 'KeyboardInterrupt' object has no attribute '_render_traceback_'\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"C:\\Users\\JeongBeomJin\\Anaconda3\\envs\\OpenCV\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1148, in get_records\n",
            "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
            "  File \"C:\\Users\\JeongBeomJin\\Anaconda3\\envs\\OpenCV\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 316, in wrapped\n",
            "    return f(*args, **kwargs)\n",
            "  File \"C:\\Users\\JeongBeomJin\\Anaconda3\\envs\\OpenCV\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 350, in _fixed_getinnerframes\n",
            "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
            "  File \"C:\\Users\\JeongBeomJin\\Anaconda3\\envs\\OpenCV\\lib\\inspect.py\", line 1502, in getinnerframes\n",
            "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
            "  File \"C:\\Users\\JeongBeomJin\\Anaconda3\\envs\\OpenCV\\lib\\inspect.py\", line 1460, in getframeinfo\n",
            "    filename = getsourcefile(frame) or getfile(frame)\n",
            "  File \"C:\\Users\\JeongBeomJin\\Anaconda3\\envs\\OpenCV\\lib\\inspect.py\", line 696, in getsourcefile\n",
            "    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n",
            "  File \"C:\\Users\\JeongBeomJin\\Anaconda3\\envs\\OpenCV\\lib\\inspect.py\", line 739, in getmodule\n",
            "    f = getabsfile(module)\n",
            "  File \"C:\\Users\\JeongBeomJin\\Anaconda3\\envs\\OpenCV\\lib\\inspect.py\", line 708, in getabsfile\n",
            "    _filename = getsourcefile(object) or getfile(object)\n",
            "  File \"C:\\Users\\JeongBeomJin\\Anaconda3\\envs\\OpenCV\\lib\\inspect.py\", line 693, in getsourcefile\n",
            "    if os.path.exists(filename):\n",
            "  File \"C:\\Users\\JeongBeomJin\\Anaconda3\\envs\\OpenCV\\lib\\genericpath.py\", line 19, in exists\n",
            "    os.stat(path)\n",
            "KeyboardInterrupt\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ln61T8E95fus"
      },
      "source": [
        "demo_test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NKCucW-I1hVm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "91cc0ac6-b48e-4b7f-b89c-9ad0fec4163b"
      },
      "source": [
        "import cv2\n",
        "import os\n",
        "import sys\n",
        "#sys.path.append(\"/MRCNN_pure\")\n",
        "#from visualize_cv2 import model, display_instances, class_names\n",
        "import argparse\n",
        "import threading\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from flask import Flask, render_template, Response\n",
        "\n",
        "os.chdir(\"/MRCNN_pure\")\n",
        "sys.path.append(\"/MRCNN_pure\")\n",
        "  \n",
        "# Root directory of the project\n",
        "ROOT_DIR = os.path.abspath(\".\")\n",
        "\n",
        "MAXIMUM_WEIGHT = 10\n",
        "layer = 255 * np.ones((500,500,3), dtype=np.uint8)\n",
        "layer_frame = 255 * np.ones((64,64,3), dtype=np.uint8)\n",
        "logo = cv2.imread(os.path.join(ROOT_DIR, \"siren_black.jpg\"))\n",
        "\n",
        "from keras.models import load_model\n",
        "mlp_model = load_model('/MRCNN_pure/mlp_model.h5')\n",
        "  \n",
        "# Import Mask RCNN\n",
        "sys.path.append(ROOT_DIR)  # To find local version of the library\n",
        "from mrcnn import utils\n",
        "import mrcnn.model as modellib\n",
        "# Import COCO config\n",
        "sys.path.append(os.path.join(ROOT_DIR, \"samples/coco/\"))  # To find local version\n",
        "import coco\n",
        "  \n",
        "# Directory to save logs and trained model\n",
        "MODEL_DIR = os.path.join(ROOT_DIR, \"logs\")\n",
        "  \n",
        "# Local path to trained weights file\n",
        "COCO_MODEL_PATH = os.path.join(ROOT_DIR, \"mask_rcnn_coco.h5\")\n",
        "# Download COCO trained weights from Releases if needed\n",
        "if not os.path.exists(COCO_MODEL_PATH):\n",
        "    utils.download_trained_weights(COCO_MODEL_PATH)\n",
        "  \n",
        "  \n",
        "class InferenceConfig(coco.CocoConfig):\n",
        "    # Set batch size to 1 since we'll be running inference on\n",
        "    # one image at a time. Batch size = GPU_COUNT * IMAGES_PER_GPU\n",
        "    GPU_COUNT = 1\n",
        "    IMAGES_PER_GPU = 1\n",
        "  \n",
        "config = InferenceConfig()\n",
        "config.display()\n",
        "  \n",
        "# Create model object in inference mode.\n",
        "model = modellib.MaskRCNN(mode=\"inference\", model_dir=MODEL_DIR, config=config)\n",
        "  \n",
        "# Load weights trained on MS-COCO\n",
        "model.load_weights(COCO_MODEL_PATH, by_name=True)\n",
        "  \n",
        "# COCO Class names\n",
        "# Index of the class in the list is its ID. For example, to get ID of\n",
        "# the teddy bear class, use: class_names.index('teddy bear')\n",
        "class_names = ['BG', 'person', 'bicycle', 'car', 'motorcycle', 'airplane',\n",
        "               'bus', 'train', 'truck', 'boat', 'traffic light',\n",
        "               'fire hydrant', 'stop sign', 'parking meter', 'bench', 'bird',\n",
        "               'cat', 'dog', 'horse', 'sheep', 'cow', 'elephant', 'bear',\n",
        "               'zebra', 'giraffe', 'backpack', 'umbrella', 'handbag', 'tie',\n",
        "               'suitcase', 'frisbee', 'skis', 'snowboard', 'sports ball',\n",
        "               'kite', 'baseball bat', 'baseball glove', 'skateboard',\n",
        "               'surfboard', 'tennis racket', 'bottle', 'wine glass', 'cup',\n",
        "               'fork', 'knife', 'spoon', 'bowl', 'banana', 'apple',\n",
        "               'sandwich', 'orange', 'broccoli', 'carrot', 'hot dog', 'pizza',\n",
        "               'donut', 'cake', 'chair', 'couch', 'potted plant', 'bed',\n",
        "               'dining table', 'toilet', 'tv', 'laptop', 'mouse', 'remote',\n",
        "               'keyboard', 'cell phone', 'microwave', 'oven', 'toaster',\n",
        "               'sink', 'refrigerator', 'book', 'clock', 'vase', 'scissors',\n",
        "               'teddy bear', 'hair drier', 'toothbrush']\n",
        "\n",
        "def random_colors(N):\n",
        "    np.random.seed(1)\n",
        "    colors = [tuple(255 * np.random.rand(3)) for _ in range(N)]\n",
        "    return colors\n",
        "\n",
        "colors = random_colors(len(class_names))\n",
        "class_dict = {\n",
        "    name: color for name, color in zip(class_names, colors)\n",
        "}\n",
        "\n",
        "def apply_mask(image, mask, color, alpha=0.5):\n",
        "    \"\"\"apply mask to image\"\"\"\n",
        "    for n, c in enumerate(color):\n",
        "        image[:, :, n] = np.where(\n",
        "            mask == 1,\n",
        "            image[:, :, n] * (1 - alpha) + alpha * c,\n",
        "            image[:, :, n]\n",
        "        )\n",
        "    return image\n",
        "\n",
        "def apply_mask2(image, mask, num=2):\n",
        "    image[:, :] = np.where(\n",
        "        mask == 1,\n",
        "        image[:, :] +num,\n",
        "        image[:, :]\n",
        "    )\n",
        "    return image    \n",
        "\n",
        "def img_overlay(background, logo, height, xpos, ypos):\n",
        "    logo_height = int(height / 7)\n",
        "    logo = cv2.resize(logo, (logo_height, logo_height))\n",
        "\n",
        "    gray_logo = cv2.cvtColor(logo, cv2.COLOR_BGR2GRAY)\n",
        "    _, mask_inv = cv2.threshold(gray_logo, 10, 255, cv2.THRESH_BINARY_INV)\n",
        "\n",
        "\n",
        "    background_height, background_width, _ = background.shape # 400, 520, 3\n",
        "    logo_height, logo_width, _ = logo.shape # 308, 250, 3\n",
        "\n",
        "    x = xpos\n",
        "    y = ypos\n",
        "\n",
        "    roi = background[x: x+logo_height, y: y+logo_width]\n",
        "\n",
        "    roi_logo = cv2.add(logo, roi, mask=mask_inv)\n",
        "    result = cv2.add(roi_logo, logo)\n",
        "    np.copyto(roi, result)\n",
        "    return background\n",
        "\n",
        "def display_instances(image, boxes, masks, ids, names, scores):\n",
        "    \"\"\"\n",
        "        take the image and results and apply the mask, box, and Label\n",
        "    \"\"\"\n",
        "    os.chdir(\"/MRCNN_pure\")\n",
        "    n_instances = boxes.shape[0]\n",
        "    isEmergency = 0\n",
        "    emergencyImage = image\n",
        "\n",
        "    if not n_instances:\n",
        "        print('NO INSTANCES TO DISPLAY')\n",
        "    else:\n",
        "        assert boxes.shape[0] == masks.shape[-1] == ids.shape[0]\n",
        "\n",
        "    for i in range(n_instances):\n",
        "        if not np.any(boxes[i]):\n",
        "            continue\n",
        "        if not (ids[i] == 1) :\n",
        "            continue\n",
        "        print('test27')\n",
        "        image = cv2.UMat(image)\n",
        "        image = cv2.UMat.get(image)\n",
        "        height = image.shape[0]\n",
        "        width = image.shape[1]\n",
        "\n",
        "        mask_list = []\n",
        "        y1, x1, y2, x2 = boxes[i]\n",
        "        label = names[ids[i]]\n",
        "        color = class_dict[label]\n",
        "        score = scores[i] if scores is not None else None\n",
        "        caption = '{} {:.2f}'.format(label, score) if score else label\n",
        "        mask = masks[:, :, i]\n",
        "        mask_list.append(mask)\n",
        "\n",
        "        global layer\n",
        "        global layer_frame\n",
        "        global weight_frame\n",
        "\n",
        "        black = [0, 0, 0]\n",
        "        red = [0, 0, 255]\n",
        "\n",
        "        weight_frame = apply_mask2(weight_frame, mask)\n",
        "        weight_frame[weight_frame>=MAXIMUM_WEIGHT] = MAXIMUM_WEIGHT\n",
        "\n",
        "\n",
        "        current_frame = np.zeros((height,width), dtype=np.uint8)\n",
        "        current_frame = apply_mask2(current_frame, mask, num = MAXIMUM_WEIGHT)\n",
        "        current_frame[current_frame==0] = 255\n",
        "\n",
        "        pixel_count = np.count_nonzero(current_frame==MAXIMUM_WEIGHT)\n",
        "        print(\"Current frame pixels : \", pixel_count)\n",
        "        same_pixel = np.count_nonzero(current_frame==weight_frame)\n",
        "        print(\"Same pixels: \", same_pixel)\n",
        "        frame_acc = same_pixel / pixel_count\n",
        "        print(\"Frame acc: \", frame_acc)\n",
        "\n",
        "        layer = 255 * np.ones((height,width,3), dtype=np.uint8)\n",
        "        layer = apply_mask(layer, mask, black, alpha=0.8)\n",
        "        layer = layer[y1:y2, x1:x2, :]\n",
        "        layer_height = layer.shape[0]\n",
        "        layer_width = layer.shape[1]\n",
        "        if(layer_height >= layer_width) :\n",
        "          scale_percent = 64 / layer_height\n",
        "          new_height = int(layer_height * scale_percent)\n",
        "          new_width = int(layer_width * scale_percent)\n",
        "          layer = cv2.resize(layer, dsize=(new_width, new_height), interpolation=cv2.INTER_CUBIC)\n",
        "          layer_frame = 255 * np.ones((64,64,3), dtype=np.uint8)\n",
        "          #layer_frame[0:new_width, 32-(new_height//2):32+(new_height//2),:] = layer\n",
        "          rows, cols, channels = layer.shape\n",
        "          layer_frame[0:rows, 32-(cols//2):32-(cols//2) + cols] = layer\n",
        "        else :\n",
        "          scale_percent = 64 / layer_width\n",
        "          new_height = int(layer_height * scale_percent)\n",
        "          new_width = int(layer_width * scale_percent)\n",
        "          layer = cv2.resize(layer, dsize=(new_width, new_height), interpolation=cv2.INTER_CUBIC)\n",
        "          layer_frame = 255 * np.ones((64,64,3), dtype=np.uint8)\n",
        "          #layer_frame[32-(new_width//2):32+(new_width//2), 0:new_height,:] = layer\n",
        "          rows, cols, channels = layer.shape\n",
        "          layer_frame[32-(rows//2):32-(rows//2) + rows, 0:cols] = layer\n",
        "\n",
        "        backup = layer_frame\n",
        "        layer_frame = cv2.cvtColor(layer_frame, cv2.COLOR_BGR2GRAY)\n",
        "        layer_frame = ~layer_frame\n",
        "\n",
        "        predict_test = layer_frame\n",
        "        predict_test = predict_test.reshape(1, 4096)\n",
        "\n",
        "        result = mlp_model.predict(predict_test)\n",
        "        label_index = np.argmax(result)\n",
        "\n",
        "        rows, cols = np.where(weight_frame >= 10)\n",
        "        print(rows, cols)\n",
        "\n",
        "        image = apply_mask(image, mask, color)\n",
        "\n",
        "        contour_frame = np.zeros((height,width), dtype=np.uint8)\n",
        "        contour_frame = apply_mask2(contour_frame, mask, num=255)\n",
        "        ret, thr = cv2.threshold(contour_frame, 127, 255, 0)\n",
        "        contours, _ = cv2.findContours(thr, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
        "        \n",
        "        \n",
        "        if frame_acc >= 0.7 and label_index != 1:\n",
        "          isEmergency = 1\n",
        "\n",
        "        if (label_index != 1) :\n",
        "          caption = 'EMergency! {} {:.2f}'.format(label, score) if score else label\n",
        "          #image = cv2.rectangle(image, (x1, y1), (x2, y2), red, 2)\n",
        "          if isEmergency == 1:\n",
        "            emergencyImage = image[y1:y2, x1:x2, :]\n",
        "            cv2.drawContours(image, contours, -1, (0,0,255), 1)\n",
        "          else :\n",
        "            cv2.drawContours(image, contours, -1, (0,255,255), 1)\n",
        "        else :\n",
        "          cv2.drawContours(image, contours, -1, (0,255,0), 1)\n",
        "          #image = cv2.rectangle(image, (x1, y1), (x2, y2), color, 2)\n",
        "        image = cv2.putText(\n",
        "            image, caption, (x1, y1), cv2.FONT_HERSHEY_COMPLEX, 0.7, color, 2\n",
        "        )\n",
        "\n",
        "\n",
        "    print(np.max(weight_frame))\n",
        "    weight_frame[weight_frame>=1] -= 1\n",
        "    global logo\n",
        "    if isEmergency == 1:\n",
        "      image = img_overlay(image, logo, image.shape[0], 0, 0)\n",
        "\n",
        "    return image, emergencyImage, isEmergency\n",
        "\n",
        "capture = cv2.VideoCapture(os.path.join(ROOT_DIR, \"test13.mp4\"))\n",
        "\n",
        "(grabbed, frame) = capture.read()\n",
        "image_h = frame.shape[0]\n",
        "image_w = frame.shape[1]\n",
        "weight_frame = np.zeros((image_h,image_w), dtype=np.uint8)\n",
        "_lock = threading.Lock() # 쓰레딩 시 사용되는 lock\n",
        "\n",
        "frame_for_crop = None # 응급 상황 크롭 이미지 변수\n",
        "emer_for_bool = 0 # 응급상황 여부 변수. 0이면 정상, 1이면 응급 상황\n",
        "frame_for_screen = None # 현재 영상 이미지 변수\n",
        "\n",
        "app = Flask(__name__)\n",
        "\n",
        "@app.route(\"/\")\n",
        "def main():\n",
        "  return render_template('index.html')\n",
        "\n",
        "# 영상 프레임 처리 후 결과 반환 쓰레드\n",
        "def webcam(capture):\n",
        "  global frame_for_screen, _lock, emer_for_bool, frame_for_crop\n",
        "\n",
        "  while True:\n",
        "    grabbed, frame = capture.read()\n",
        "    frame_pos = capture.get(cv2.CAP_PROP_POS_FRAMES)\n",
        "    frame_count = capture.get(cv2.CAP_PROP_FRAME_COUNT)\n",
        "    if not grabbed:\n",
        "      print (\"Not grabbed.\")\n",
        "    \n",
        "    if ((frame_pos%25) == 0): \n",
        "      results = model.detect([frame], verbose=1)\n",
        "      \n",
        "      # Visualize results\n",
        "      r = results[0]\n",
        "      masked_frame , masked_list, isEmergency = display_instances(frame, r['rois'], r['masks'], r['class_ids'],\n",
        "                                class_names, r['scores'])\n",
        "      \n",
        "      with _lock:\n",
        "        frame_for_screen = masked_frame.copy()\n",
        "        frame_for_crop = masked_list.copy()\n",
        "        emer_for_bool = isEmergency\n",
        "\n",
        "# 현재 영상의 프레임을 스크린에 띄워주는 제너레이터\n",
        "def generate():\n",
        "\n",
        "    global frame_for_screen, _lock\n",
        "\n",
        "    while True:\n",
        "      with _lock:\n",
        "        if frame_for_screen is None:\n",
        "          continue\n",
        "        \n",
        "        encode_param=[int(cv2.IMWRITE_JPEG_QUALITY), 90]\n",
        "        (flag, encodedImage) = cv2.imencode(\".jpg\", frame_for_screen, encode_param)\n",
        "        if not flag:\n",
        "          continue\n",
        "      \n",
        "      yield (b'--frame\\r\\n' b'Content-Type: image/jpeg\\r\\n\\r\\n' + bytearray(encodedImage) + b'\\r\\n')\n",
        "\n",
        "\n",
        "@app.route(\"/video_feed\")\n",
        "def video_feed():\n",
        "  return Response(generate(), mimetype = \"multipart/x-mixed-replace; boundary=frame\")\n",
        "\n",
        "\n",
        "# 응급상황의 크롭 이미지를 띄워주는 제너레이터\n",
        "def emergency():\n",
        "  global emer_for_bool, frame_for_crop\n",
        "  count = 0\n",
        "  while True:\n",
        "    with _lock:\n",
        "      if emer_for_bool==1 and (count==0 or count==1):\n",
        "        encode_param=[int(cv2.IMWRITE_JPEG_QUALITY), 90]\n",
        "        flag, encodedImage = cv2.imencode(\".jpg\", frame_for_crop, encode_param)\n",
        "        yield (b'--frame\\r\\n' b'Content-Type: image/jpeg\\r\\n\\r\\n' + bytearray(encodedImage) + b'\\r\\n')\n",
        "        count+=1\n",
        "        continue\n",
        "      elif emer_for_bool==1 and count==1:\n",
        "        count=2\n",
        "      elif emer_for_bool==0:\n",
        "        count=0\n",
        "  \n",
        "\n",
        "@app.route(\"/isEmg\")\n",
        "def isEmg():\n",
        "  return Response(emergency(), mimetype = \"multipart/x-mixed-replace; boundary=frame\")\n",
        "print('server start')\n",
        "\n",
        "# 응급상황의 여부를 로그로 알려주는 제너레이터\n",
        "def log_gen():\n",
        "  global emer_for_bool\n",
        "\n",
        "  if emer_for_bool==1:\n",
        "    emer_for_text = \"emergency\"\n",
        "    yield emer_for_text\n",
        "  else :\n",
        "    emer_for_text = \"normal\"\n",
        "    yield emer_for_text\n",
        "    \n",
        "@app.route(\"/for_log\")\n",
        "def for_log():\n",
        "  return Response(log_gen())\n",
        "\n",
        "# 경고상황의 여부를 로그로 알려주는 제너레이터\n",
        "def log_gen_warn():\n",
        "  global emer_for_bool, weight_frame\n",
        "\n",
        "  if (emer_for_bool==0) and (np.max(weight_frame)== MAXIMUM_WEIGHT):\n",
        "    emer_for_text = \"warning\"\n",
        "    yield emer_for_text\n",
        "    \n",
        "@app.route(\"/for_warn_log\")\n",
        "def for_warn_log():\n",
        "  return Response(log_gen_warn())\n",
        "\n",
        "args = sys.argv\n",
        "if(len(args) <2):\n",
        "  print(\"run command: python or video: file name\")\n",
        "  sys.exit(0) \n",
        "name = args[1]\n",
        "if(len(args[1]) == 0):\n",
        "  name = int(args[1])\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "# 쓰레딩 시작  \n",
        "  threading.Thread(target=app.run).start()\n",
        "  threading.Thread(target=webcam(capture)).start()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From C:\\Users\\JeongBeomJin\\Anaconda3\\envs\\OpenCV\\lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n",
            "WARNING:tensorflow:From C:\\Users\\JeongBeomJin\\Anaconda3\\envs\\OpenCV\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "\n",
            "Configurations:\n",
            "BACKBONE                       resnet101\n",
            "BACKBONE_STRIDES               [4, 8, 16, 32, 64]\n",
            "BATCH_SIZE                     1\n",
            "BBOX_STD_DEV                   [0.1 0.1 0.2 0.2]\n",
            "COMPUTE_BACKBONE_SHAPE         None\n",
            "DETECTION_MAX_INSTANCES        100\n",
            "DETECTION_MIN_CONFIDENCE       0.7\n",
            "DETECTION_NMS_THRESHOLD        0.3\n",
            "FPN_CLASSIF_FC_LAYERS_SIZE     1024\n",
            "GPU_COUNT                      1\n",
            "GRADIENT_CLIP_NORM             5.0\n",
            "IMAGES_PER_GPU                 1\n",
            "IMAGE_CHANNEL_COUNT            3\n",
            "IMAGE_MAX_DIM                  1024\n",
            "IMAGE_META_SIZE                93\n",
            "IMAGE_MIN_DIM                  800\n",
            "IMAGE_MIN_SCALE                0\n",
            "IMAGE_RESIZE_MODE              square\n",
            "IMAGE_SHAPE                    [1024 1024    3]\n",
            "LEARNING_MOMENTUM              0.9\n",
            "LEARNING_RATE                  0.001\n",
            "LOSS_WEIGHTS                   {'rpn_class_loss': 1.0, 'rpn_bbox_loss': 1.0, 'mrcnn_class_loss': 1.0, 'mrcnn_bbox_loss': 1.0, 'mrcnn_mask_loss': 1.0}\n",
            "MASK_POOL_SIZE                 14\n",
            "MASK_SHAPE                     [28, 28]\n",
            "MAX_GT_INSTANCES               100\n",
            "MEAN_PIXEL                     [123.7 116.8 103.9]\n",
            "MINI_MASK_SHAPE                (56, 56)\n",
            "NAME                           coco\n",
            "NUM_CLASSES                    81\n",
            "POOL_SIZE                      7\n",
            "POST_NMS_ROIS_INFERENCE        1000\n",
            "POST_NMS_ROIS_TRAINING         2000\n",
            "PRE_NMS_LIMIT                  6000\n",
            "ROI_POSITIVE_RATIO             0.33\n",
            "RPN_ANCHOR_RATIOS              [0.5, 1, 2]\n",
            "RPN_ANCHOR_SCALES              (32, 64, 128, 256, 512)\n",
            "RPN_ANCHOR_STRIDE              1\n",
            "RPN_BBOX_STD_DEV               [0.1 0.1 0.2 0.2]\n",
            "RPN_NMS_THRESHOLD              0.7\n",
            "RPN_TRAIN_ANCHORS_PER_IMAGE    256\n",
            "STEPS_PER_EPOCH                1000\n",
            "TOP_DOWN_PYRAMID_SIZE          256\n",
            "TRAIN_BN                       False\n",
            "TRAIN_ROIS_PER_IMAGE           200\n",
            "USE_MINI_MASK                  True\n",
            "USE_RPN_ROIS                   True\n",
            "VALIDATION_STEPS               50\n",
            "WEIGHT_DECAY                   0.0001\n",
            "\n",
            "\n",
            "WARNING:tensorflow:From C:\\MRCNN_pure\\mrcnn\\model.py:772: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "server start\n",
            " * Serving Flask app \"__main__\" (lazy loading)\n",
            " * Environment: production\n",
            "   WARNING: This is a development server. Do not use it in a production deployment.\n",
            "   Use a production WSGI server instead.\n",
            " * Debug mode: off\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " * Running on http://127.0.0.1:5000/ (Press CTRL+C to quit)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Processing 1 images\n",
            "image                    shape: (480, 852, 3)         min:    0.00000  max:  255.00000  uint8\n",
            "molded_images            shape: (1, 1024, 1024, 3)    min: -123.70000  max:  151.10000  float64\n",
            "image_metas              shape: (1, 93)               min:    0.00000  max: 1024.00000  float64\n",
            "anchors                  shape: (1, 261888, 4)        min:   -0.35390  max:    1.29134  float32\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "127.0.0.1 - - [25/Nov/2020 16:15:11] \"\u001b[37mGET / HTTP/1.1\u001b[0m\" 200 -\n",
            "127.0.0.1 - - [25/Nov/2020 16:15:12] \"\u001b[37mGET /for_log HTTP/1.1\u001b[0m\" 200 -\n",
            "127.0.0.1 - - [25/Nov/2020 16:15:13] \"\u001b[37mGET /for_log HTTP/1.1\u001b[0m\" 200 -\n",
            "127.0.0.1 - - [25/Nov/2020 16:15:14] \"\u001b[37mGET /for_log HTTP/1.1\u001b[0m\" 200 -\n",
            "127.0.0.1 - - [25/Nov/2020 16:15:15] \"\u001b[37mGET /for_log HTTP/1.1\u001b[0m\" 200 -\n",
            "127.0.0.1 - - [25/Nov/2020 16:15:19] \"\u001b[37mGET /for_log HTTP/1.1\u001b[0m\" 200 -\n",
            "127.0.0.1 - - [25/Nov/2020 16:15:19] \"\u001b[37mGET /for_log HTTP/1.1\u001b[0m\" 200 -\n",
            "127.0.0.1 - - [25/Nov/2020 16:15:19] \"\u001b[37mGET /for_log HTTP/1.1\u001b[0m\" 200 -\n",
            "127.0.0.1 - - [25/Nov/2020 16:15:19] \"\u001b[37mGET /for_log HTTP/1.1\u001b[0m\" 200 -\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "test27\n",
            "Current frame pixels :  1986\n",
            "Same pixels:  0\n",
            "Frame acc:  0.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "127.0.0.1 - - [25/Nov/2020 16:15:21] \"\u001b[37mGET /video_feed HTTP/1.1\u001b[0m\" 200 -\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[] []\n",
            "2\n",
            "Processing 1 images\n",
            "image                    shape: (480, 852, 3)         min:    0.00000  max:  255.00000  uint8\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "127.0.0.1 - - [25/Nov/2020 16:15:21] \"\u001b[37mGET /for_log HTTP/1.1\u001b[0m\" 200 -\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "molded_images            shape: (1, 1024, 1024, 3)    min: -123.70000  max:  151.10000  float64\n",
            "image_metas              shape: (1, 93)               min:    0.00000  max: 1024.00000  float64\n",
            "anchors                  shape: (1, 261888, 4)        min:   -0.35390  max:    1.29134  float32\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "127.0.0.1 - - [25/Nov/2020 16:15:22] \"\u001b[37mGET /for_log HTTP/1.1\u001b[0m\" 200 -\n",
            "127.0.0.1 - - [25/Nov/2020 16:15:22] \"\u001b[37mGET /for_warn_log HTTP/1.1\u001b[0m\" 200 -\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "test27\n",
            "Current frame pixels :  1972\n",
            "Same pixels:  0\n",
            "Frame acc:  0.0\n",
            "[] []\n",
            "2\n",
            "Processing 1 images\n",
            "image                    shape: (480, 852, 3)         min:    0.00000  max:  255.00000  uint8\n",
            "molded_images            shape: (1, 1024, 1024, 3)    min: -123.70000  max:  151.10000  float64\n",
            "image_metas              shape: (1, 93)               min:    0.00000  max: 1024.00000  float64\n",
            "anchors                  shape: (1, 261888, 4)        min:   -0.35390  max:    1.29134  float32\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "127.0.0.1 - - [25/Nov/2020 16:15:23] \"\u001b[37mGET /for_log HTTP/1.1\u001b[0m\" 200 -\n",
            "127.0.0.1 - - [25/Nov/2020 16:15:24] \"\u001b[37mGET /for_log HTTP/1.1\u001b[0m\" 200 -\n",
            "127.0.0.1 - - [25/Nov/2020 16:15:24] \"\u001b[37mGET /for_log HTTP/1.1\u001b[0m\" 200 -\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "test27\n",
            "Current frame pixels :  1817\n",
            "Same pixels:  0\n",
            "Frame acc:  0.0\n",
            "[] []\n",
            "2\n",
            "Processing 1 images\n",
            "image                    shape: (480, 852, 3)         min:    0.00000  max:  255.00000  uint8\n",
            "molded_images            shape: (1, 1024, 1024, 3)    min: -123.70000  max:  151.10000  float64\n",
            "image_metas              shape: (1, 93)               min:    0.00000  max: 1024.00000  float64\n",
            "anchors                  shape: (1, 261888, 4)        min:   -0.35390  max:    1.29134  float32\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "127.0.0.1 - - [25/Nov/2020 16:15:25] \"\u001b[37mGET /for_log HTTP/1.1\u001b[0m\" 200 -\n",
            "127.0.0.1 - - [25/Nov/2020 16:15:26] \"\u001b[37mGET /for_log HTTP/1.1\u001b[0m\" 200 -\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "test27\n",
            "Current frame pixels :  1601\n",
            "Same pixels:  0\n",
            "Frame acc:  0.0\n",
            "[] []\n",
            "2\n",
            "Processing 1 images\n",
            "image                    shape: (480, 852, 3)         min:    0.00000  max:  255.00000  uint8\n",
            "molded_images            shape: (1, 1024, 1024, 3)    min: -123.70000  max:  151.10000  float64\n",
            "image_metas              shape: (1, 93)               min:    0.00000  max: 1024.00000  float64\n",
            "anchors                  shape: (1, 261888, 4)        min:   -0.35390  max:    1.29134  float32\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "127.0.0.1 - - [25/Nov/2020 16:15:27] \"\u001b[37mGET /for_log HTTP/1.1\u001b[0m\" 200 -\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "test27\n",
            "Current frame pixels :  1762\n",
            "Same pixels:  0\n",
            "Frame acc:  0.0\n",
            "[] []\n",
            "2\n",
            "Processing 1 images\n",
            "image                    shape: (480, 852, 3)         min:    0.00000  max:  255.00000  uint8\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "127.0.0.1 - - [25/Nov/2020 16:15:28] \"\u001b[37mGET /for_log HTTP/1.1\u001b[0m\" 200 -\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "molded_images            shape: (1, 1024, 1024, 3)    min: -123.70000  max:  151.10000  float64\n",
            "image_metas              shape: (1, 93)               min:    0.00000  max: 1024.00000  float64\n",
            "anchors                  shape: (1, 261888, 4)        min:   -0.35390  max:    1.29134  float32\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "127.0.0.1 - - [25/Nov/2020 16:15:29] \"\u001b[37mGET /for_log HTTP/1.1\u001b[0m\" 200 -\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "test27\n",
            "Current frame pixels :  1860\n",
            "Same pixels:  0\n",
            "Frame acc:  0.0\n",
            "[] []\n",
            "2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "127.0.0.1 - - [25/Nov/2020 16:15:30] \"\u001b[37mGET /for_log HTTP/1.1\u001b[0m\" 200 -\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Processing 1 images\n",
            "image                    shape: (480, 852, 3)         min:    0.00000  max:  255.00000  uint8\n",
            "molded_images            shape: (1, 1024, 1024, 3)    min: -123.70000  max:  151.10000  float64\n",
            "image_metas              shape: (1, 93)               min:    0.00000  max: 1024.00000  float64\n",
            "anchors                  shape: (1, 261888, 4)        min:   -0.35390  max:    1.29134  float32\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "127.0.0.1 - - [25/Nov/2020 16:15:31] \"\u001b[37mGET /for_log HTTP/1.1\u001b[0m\" 200 -\n",
            "127.0.0.1 - - [25/Nov/2020 16:15:31] \"\u001b[37mGET /for_warn_log HTTP/1.1\u001b[0m\" 200 -\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "test27\n",
            "Current frame pixels :  1780\n",
            "Same pixels:  0\n",
            "Frame acc:  0.0\n",
            "[] []\n",
            "2\n",
            "Processing 1 images\n",
            "image                    shape: (480, 852, 3)         min:    0.00000  max:  255.00000  uint8\n",
            "molded_images            shape: (1, 1024, 1024, 3)    min: -123.70000  max:  151.10000  float64\n",
            "image_metas              shape: (1, 93)               min:    0.00000  max: 1024.00000  float64\n",
            "anchors                  shape: (1, 261888, 4)        min:   -0.35390  max:    1.29134  float32\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "127.0.0.1 - - [25/Nov/2020 16:15:32] \"\u001b[37mGET /for_log HTTP/1.1\u001b[0m\" 200 -\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "test27\n",
            "Current frame pixels :  1566\n",
            "Same pixels:  0\n",
            "Frame acc:  0.0\n",
            "[] []\n",
            "2\n",
            "Processing 1 images\n",
            "image                    shape: (480, 852, 3)         min:    0.00000  max:  255.00000  uint8\n",
            "molded_images            shape: (1, 1024, 1024, 3)    min: -123.70000  max:  151.10000  float64\n",
            "image_metas              shape: (1, 93)               min:    0.00000  max: 1024.00000  float64\n",
            "anchors                  shape: (1, 261888, 4)        min:   -0.35390  max:    1.29134  float32\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "127.0.0.1 - - [25/Nov/2020 16:15:34] \"\u001b[37mGET /for_log HTTP/1.1\u001b[0m\" 200 -\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "test27\n",
            "Current frame pixels :  1547\n",
            "Same pixels:  0\n",
            "Frame acc:  0.0\n",
            "[] []\n",
            "2\n",
            "Processing 1 images\n",
            "image                    shape: (480, 852, 3)         min:    0.00000  max:  255.00000  uint8\n",
            "molded_images            shape: (1, 1024, 1024, 3)    min: -123.70000  max:  151.10000  float64\n",
            "image_metas              shape: (1, 93)               min:    0.00000  max: 1024.00000  float64\n",
            "anchors                  shape: (1, 261888, 4)        min:   -0.35390  max:    1.29134  float32\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "127.0.0.1 - - [25/Nov/2020 16:15:35] \"\u001b[37mGET /for_log HTTP/1.1\u001b[0m\" 200 -\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1\n",
            "Processing 1 images\n",
            "image                    shape: (480, 852, 3)         min:    0.00000  max:  255.00000  uint8\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "127.0.0.1 - - [25/Nov/2020 16:15:36] \"\u001b[37mGET /for_log HTTP/1.1\u001b[0m\" 200 -\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "molded_images            shape: (1, 1024, 1024, 3)    min: -123.70000  max:  151.10000  float64\n",
            "image_metas              shape: (1, 93)               min:    0.00000  max: 1024.00000  float64\n",
            "anchors                  shape: (1, 261888, 4)        min:   -0.35390  max:    1.29134  float32\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "127.0.0.1 - - [25/Nov/2020 16:15:37] \"\u001b[37mGET /for_log HTTP/1.1\u001b[0m\" 200 -\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "test27\n",
            "Current frame pixels :  1510\n",
            "Same pixels:  0\n",
            "Frame acc:  0.0\n",
            "[] []\n",
            "2\n",
            "Processing 1 images\n",
            "image                    shape: (480, 852, 3)         min:    0.00000  max:  255.00000  uint8\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "127.0.0.1 - - [25/Nov/2020 16:15:38] \"\u001b[37mGET /for_log HTTP/1.1\u001b[0m\" 200 -\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "molded_images            shape: (1, 1024, 1024, 3)    min: -123.70000  max:  151.10000  float64\n",
            "image_metas              shape: (1, 93)               min:    0.00000  max: 1024.00000  float64\n",
            "anchors                  shape: (1, 261888, 4)        min:   -0.35390  max:    1.29134  float32\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "127.0.0.1 - - [25/Nov/2020 16:15:39] \"\u001b[37mGET /for_log HTTP/1.1\u001b[0m\" 200 -\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "test27\n",
            "Current frame pixels :  1420\n",
            "Same pixels:  0\n",
            "Frame acc:  0.0\n",
            "[] []\n",
            "3\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "127.0.0.1 - - [25/Nov/2020 16:15:39] \"\u001b[37mGET /for_log HTTP/1.1\u001b[0m\" 200 -\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Processing 1 images\n",
            "image                    shape: (480, 852, 3)         min:    0.00000  max:  255.00000  uint8\n",
            "molded_images            shape: (1, 1024, 1024, 3)    min: -123.70000  max:  151.10000  float64\n",
            "image_metas              shape: (1, 93)               min:    0.00000  max: 1024.00000  float64\n",
            "anchors                  shape: (1, 261888, 4)        min:   -0.35390  max:    1.29134  float32\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "127.0.0.1 - - [25/Nov/2020 16:15:40] \"\u001b[37mGET /for_log HTTP/1.1\u001b[0m\" 200 -\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "test27\n",
            "Current frame pixels :  1542\n",
            "Same pixels:  0\n",
            "Frame acc:  0.0\n",
            "[] []\n",
            "4\n",
            "Processing 1 images\n",
            "image                    shape: (480, 852, 3)         min:    0.00000  max:  255.00000  uint8\n",
            "molded_images            shape: (1, 1024, 1024, 3)    min: -123.70000  max:  151.10000  float64\n",
            "image_metas              shape: (1, 93)               min:    0.00000  max: 1024.00000  float64\n",
            "anchors                  shape: (1, 261888, 4)        min:   -0.35390  max:    1.29134  float32\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "127.0.0.1 - - [25/Nov/2020 16:15:41] \"\u001b[37mGET /for_log HTTP/1.1\u001b[0m\" 200 -\n",
            "127.0.0.1 - - [25/Nov/2020 16:15:41] \"\u001b[37mGET /for_warn_log HTTP/1.1\u001b[0m\" 200 -\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "test27\n",
            "Current frame pixels :  1598\n",
            "Same pixels:  0\n",
            "Frame acc:  0.0\n",
            "[] []\n",
            "5\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "127.0.0.1 - - [25/Nov/2020 16:15:42] \"\u001b[37mGET /for_log HTTP/1.1\u001b[0m\" 200 -\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Processing 1 images\n",
            "image                    shape: (480, 852, 3)         min:    0.00000  max:  255.00000  uint8\n",
            "molded_images            shape: (1, 1024, 1024, 3)    min: -123.70000  max:  151.10000  float64\n",
            "image_metas              shape: (1, 93)               min:    0.00000  max: 1024.00000  float64\n",
            "anchors                  shape: (1, 261888, 4)        min:   -0.35390  max:    1.29134  float32\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "127.0.0.1 - - [25/Nov/2020 16:15:43] \"\u001b[37mGET /for_log HTTP/1.1\u001b[0m\" 200 -\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "test27\n",
            "Current frame pixels :  1636\n",
            "Same pixels:  0\n",
            "Frame acc:  0.0\n",
            "[] []\n",
            "6\n",
            "Processing 1 images\n",
            "image                    shape: (480, 852, 3)         min:    0.00000  max:  255.00000  uint8\n",
            "molded_images            shape: (1, 1024, 1024, 3)    min: -123.70000  max:  151.10000  float64\n",
            "image_metas              shape: (1, 93)               min:    0.00000  max: 1024.00000  float64\n",
            "anchors                  shape: (1, 261888, 4)        min:   -0.35390  max:    1.29134  float32\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "127.0.0.1 - - [25/Nov/2020 16:15:44] \"\u001b[37mGET /for_log HTTP/1.1\u001b[0m\" 200 -\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "test27\n",
            "Current frame pixels :  1446\n",
            "Same pixels:  0\n",
            "Frame acc:  0.0\n",
            "[] []\n",
            "7\n",
            "Processing 1 images\n",
            "image                    shape: (480, 852, 3)         min:    0.00000  max:  255.00000  uint8\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "127.0.0.1 - - [25/Nov/2020 16:15:45] \"\u001b[37mGET /for_log HTTP/1.1\u001b[0m\" 200 -\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "molded_images            shape: (1, 1024, 1024, 3)    min: -123.70000  max:  151.10000  float64\n",
            "image_metas              shape: (1, 93)               min:    0.00000  max: 1024.00000  float64\n",
            "anchors                  shape: (1, 261888, 4)        min:   -0.35390  max:    1.29134  float32\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "127.0.0.1 - - [25/Nov/2020 16:15:46] \"\u001b[37mGET /for_log HTTP/1.1\u001b[0m\" 200 -\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "test27\n",
            "Current frame pixels :  1323\n",
            "Same pixels:  0\n",
            "Frame acc:  0.0\n",
            "[] []\n",
            "8\n",
            "Processing 1 images\n",
            "image                    shape: (480, 852, 3)         min:    0.00000  max:  255.00000  uint8\n",
            "molded_images            shape: (1, 1024, 1024, 3)    min: -123.70000  max:  151.10000  float64\n",
            "image_metas              shape: (1, 93)               min:    0.00000  max: 1024.00000  float64\n",
            "anchors                  shape: (1, 261888, 4)        min:   -0.35390  max:    1.29134  float32\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "127.0.0.1 - - [25/Nov/2020 16:15:47] \"\u001b[37mGET /for_log HTTP/1.1\u001b[0m\" 200 -\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "test27\n",
            "Current frame pixels :  1597\n",
            "Same pixels:  0\n",
            "Frame acc:  0.0\n",
            "[] []\n",
            "9\n",
            "Processing 1 images\n",
            "image                    shape: (480, 852, 3)         min:    0.00000  max:  255.00000  uint8\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "127.0.0.1 - - [25/Nov/2020 16:15:48] \"\u001b[37mGET /for_log HTTP/1.1\u001b[0m\" 200 -\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "molded_images            shape: (1, 1024, 1024, 3)    min: -123.70000  max:  151.10000  float64\n",
            "image_metas              shape: (1, 93)               min:    0.00000  max: 1024.00000  float64\n",
            "anchors                  shape: (1, 261888, 4)        min:   -0.35390  max:    1.29134  float32\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "127.0.0.1 - - [25/Nov/2020 16:15:49] \"\u001b[37mGET /for_log HTTP/1.1\u001b[0m\" 200 -\n",
            "127.0.0.1 - - [25/Nov/2020 16:15:49] \"\u001b[37mGET /isEmg HTTP/1.1\u001b[0m\" 200 -\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "test27\n",
            "Current frame pixels :  1502\n",
            "Same pixels:  1181\n",
            "Frame acc:  0.7862849533954727\n",
            "[164 164 164 ... 200 200 200] [75 76 77 ... 95 96 97]\n",
            "10\n",
            "Processing 1 images\n",
            "image                    shape: (480, 852, 3)         min:    0.00000  max:  255.00000  uint8\n",
            "molded_images            shape: (1, 1024, 1024, 3)    min: -123.70000  max:  151.10000  float64\n",
            "image_metas              shape: (1, 93)               min:    0.00000  max: 1024.00000  float64\n",
            "anchors                  shape: (1, 261888, 4)        min:   -0.35390  max:    1.29134  float32\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "127.0.0.1 - - [25/Nov/2020 16:15:50] \"\u001b[37mGET /for_log HTTP/1.1\u001b[0m\" 200 -\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "test27\n",
            "Current frame pixels :  1480\n",
            "Same pixels:  1193\n",
            "Frame acc:  0.8060810810810811\n",
            "[164 164 164 ... 200 200 200] [75 76 77 ... 95 96 97]\n",
            "10\n",
            "Processing 1 images\n",
            "image                    shape: (480, 852, 3)         min:    0.00000  max:  255.00000  uint8\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "127.0.0.1 - - [25/Nov/2020 16:15:51] \"\u001b[37mGET /for_log HTTP/1.1\u001b[0m\" 200 -\n",
            "127.0.0.1 - - [25/Nov/2020 16:15:51] \"\u001b[37mGET /for_warn_log HTTP/1.1\u001b[0m\" 200 -\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "molded_images            shape: (1, 1024, 1024, 3)    min: -123.70000  max:  151.10000  float64\n",
            "image_metas              shape: (1, 93)               min:    0.00000  max: 1024.00000  float64\n",
            "anchors                  shape: (1, 261888, 4)        min:   -0.35390  max:    1.29134  float32\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "127.0.0.1 - - [25/Nov/2020 16:15:52] \"\u001b[37mGET /for_log HTTP/1.1\u001b[0m\" 200 -\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "test27\n",
            "Current frame pixels :  1520\n",
            "Same pixels:  1362\n",
            "Frame acc:  0.8960526315789473\n",
            "[164 164 164 ... 202 202 202] [74 75 76 ... 96 97 98]\n",
            "10\n",
            "Processing 1 images\n",
            "image                    shape: (480, 852, 3)         min:    0.00000  max:  255.00000  uint8\n",
            "molded_images            shape: (1, 1024, 1024, 3)    min: -123.70000  max:  151.10000  float64\n",
            "image_metas              shape: (1, 93)               min:    0.00000  max: 1024.00000  float64\n",
            "anchors                  shape: (1, 261888, 4)        min:   -0.35390  max:    1.29134  float32\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "127.0.0.1 - - [25/Nov/2020 16:15:53] \"\u001b[37mGET /for_log HTTP/1.1\u001b[0m\" 200 -\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "test27\n",
            "Current frame pixels :  1560\n",
            "Same pixels:  1351\n",
            "Frame acc:  0.8660256410256411\n",
            "[164 164 164 ... 202 202 202] [77 78 79 ... 96 97 98]\n",
            "10\n",
            "Processing 1 images\n",
            "image                    shape: (480, 852, 3)         min:    0.00000  max:  255.00000  uint8\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "127.0.0.1 - - [25/Nov/2020 16:15:54] \"\u001b[37mGET /for_log HTTP/1.1\u001b[0m\" 200 -\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "molded_images            shape: (1, 1024, 1024, 3)    min: -123.70000  max:  151.10000  float64\n",
            "image_metas              shape: (1, 93)               min:    0.00000  max: 1024.00000  float64\n",
            "anchors                  shape: (1, 261888, 4)        min:   -0.35390  max:    1.29134  float32\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "127.0.0.1 - - [25/Nov/2020 16:15:55] \"\u001b[37mGET /for_log HTTP/1.1\u001b[0m\" 200 -\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "test27\n",
            "Current frame pixels :  1564\n",
            "Same pixels:  1379\n",
            "Frame acc:  0.8817135549872123\n",
            "[164 164 164 ... 203 203 203] [77 78 79 ... 95 96 97]\n",
            "10\n",
            "Processing 1 images\n",
            "image                    shape: (480, 852, 3)         min:    0.00000  max:  255.00000  uint8\n",
            "molded_images            shape: (1, 1024, 1024, 3)    min: -123.70000  max:  151.10000  float64\n",
            "image_metas              shape: (1, 93)               min:    0.00000  max: 1024.00000  float64\n",
            "anchors                  shape: (1, 261888, 4)        min:   -0.35390  max:    1.29134  float32\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "127.0.0.1 - - [25/Nov/2020 16:15:56] \"\u001b[37mGET /for_log HTTP/1.1\u001b[0m\" 200 -\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "test27\n",
            "Current frame pixels :  1558\n",
            "Same pixels:  1387\n",
            "Frame acc:  0.8902439024390244\n",
            "[164 164 164 ... 203 203 203] [77 78 79 ... 95 96 97]\n",
            "10\n",
            "Processing 1 images\n",
            "image                    shape: (480, 852, 3)         min:    0.00000  max:  255.00000  uint8\n",
            "molded_images            shape: (1, 1024, 1024, 3)    min: -123.70000  max:  151.10000  float64\n",
            "image_metas              shape: (1, 93)               min:    0.00000  max: 1024.00000  float64\n",
            "anchors                  shape: (1, 261888, 4)        min:   -0.35390  max:    1.29134  float32\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "127.0.0.1 - - [25/Nov/2020 16:15:57] \"\u001b[37mGET /for_log HTTP/1.1\u001b[0m\" 200 -\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "test27\n",
            "Current frame pixels :  1573\n",
            "Same pixels:  1437\n",
            "Frame acc:  0.9135410044500953\n",
            "[164 164 164 ... 203 203 203] [74 75 76 ... 95 96 97]\n",
            "10\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "127.0.0.1 - - [25/Nov/2020 16:15:58] \"\u001b[37mGET /for_log HTTP/1.1\u001b[0m\" 200 -\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Processing 1 images\n",
            "image                    shape: (480, 852, 3)         min:    0.00000  max:  255.00000  uint8\n",
            "molded_images            shape: (1, 1024, 1024, 3)    min: -123.70000  max:  151.10000  float64\n",
            "image_metas              shape: (1, 93)               min:    0.00000  max: 1024.00000  float64\n",
            "anchors                  shape: (1, 261888, 4)        min:   -0.35390  max:    1.29134  float32\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "127.0.0.1 - - [25/Nov/2020 16:15:59] \"\u001b[37mGET /for_log HTTP/1.1\u001b[0m\" 200 -\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "test27\n",
            "Current frame pixels :  1472\n",
            "Same pixels:  1360\n",
            "Frame acc:  0.9239130434782609\n",
            "[164 164 164 ... 201 201 201] [74 75 76 ... 95 96 97]\n",
            "10\n",
            "Processing 1 images\n",
            "image                    shape: (480, 852, 3)         min:    0.00000  max:  255.00000  uint8\n",
            "molded_images            shape: (1, 1024, 1024, 3)    min: -123.70000  max:  151.10000  float64\n",
            "image_metas              shape: (1, 93)               min:    0.00000  max: 1024.00000  float64\n",
            "anchors                  shape: (1, 261888, 4)        min:   -0.35390  max:    1.29134  float32\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "127.0.0.1 - - [25/Nov/2020 16:16:00] \"\u001b[37mGET /for_log HTTP/1.1\u001b[0m\" 200 -\n",
            "127.0.0.1 - - [25/Nov/2020 16:16:01] \"\u001b[37mGET /for_log HTTP/1.1\u001b[0m\" 200 -\n",
            "127.0.0.1 - - [25/Nov/2020 16:16:01] \"\u001b[37mGET /for_warn_log HTTP/1.1\u001b[0m\" 200 -\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "test27\n",
            "Current frame pixels :  1610\n",
            "Same pixels:  1413\n",
            "Frame acc:  0.877639751552795\n",
            "[163 163 163 ... 200 200 200] [79 80 81 ... 96 97 98]\n",
            "10\n",
            "Processing 1 images\n",
            "image                    shape: (480, 852, 3)         min:    0.00000  max:  255.00000  uint8\n",
            "molded_images            shape: (1, 1024, 1024, 3)    min: -123.70000  max:  151.10000  float64\n",
            "image_metas              shape: (1, 93)               min:    0.00000  max: 1024.00000  float64\n",
            "anchors                  shape: (1, 261888, 4)        min:   -0.35390  max:    1.29134  float32\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "127.0.0.1 - - [25/Nov/2020 16:16:02] \"\u001b[37mGET /for_log HTTP/1.1\u001b[0m\" 200 -\n",
            "127.0.0.1 - - [25/Nov/2020 16:16:03] \"\u001b[37mGET /for_log HTTP/1.1\u001b[0m\" 200 -\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "test27\n",
            "Current frame pixels :  1560\n",
            "Same pixels:  1402\n",
            "Frame acc:  0.8987179487179487\n",
            "[163 163 163 ... 201 201 201] [79 80 81 ... 95 96 97]\n",
            "10\n",
            "Processing 1 images\n",
            "image                    shape: (480, 852, 3)         min:    0.00000  max:  255.00000  uint8\n",
            "molded_images            shape: (1, 1024, 1024, 3)    min: -123.70000  max:  151.10000  float64\n",
            "image_metas              shape: (1, 93)               min:    0.00000  max: 1024.00000  float64\n",
            "anchors                  shape: (1, 261888, 4)        min:   -0.35390  max:    1.29134  float32\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "127.0.0.1 - - [25/Nov/2020 16:16:04] \"\u001b[37mGET /for_log HTTP/1.1\u001b[0m\" 200 -\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "test27\n",
            "Current frame pixels :  1555\n",
            "Same pixels:  1394\n",
            "Frame acc:  0.8964630225080386\n",
            "[163 163 163 ... 201 201 201] [76 77 78 ... 95 96 97]\n",
            "10\n",
            "Processing 1 images\n",
            "image                    shape: (480, 852, 3)         min:    0.00000  max:  255.00000  uint8\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "127.0.0.1 - - [25/Nov/2020 16:16:05] \"\u001b[37mGET /for_log HTTP/1.1\u001b[0m\" 200 -\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "molded_images            shape: (1, 1024, 1024, 3)    min: -123.70000  max:  151.10000  float64\n",
            "image_metas              shape: (1, 93)               min:    0.00000  max: 1024.00000  float64\n",
            "anchors                  shape: (1, 261888, 4)        min:   -0.35390  max:    1.29134  float32\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "127.0.0.1 - - [25/Nov/2020 16:16:06] \"\u001b[37mGET /for_log HTTP/1.1\u001b[0m\" 200 -\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "test27\n",
            "Current frame pixels :  1486\n",
            "Same pixels:  1379\n",
            "Frame acc:  0.9279946164199192\n",
            "[163 163 163 ... 201 201 201] [76 77 78 ... 95 96 97]\n",
            "10\n",
            "Processing 1 images\n",
            "image                    shape: (480, 852, 3)         min:    0.00000  max:  255.00000  uint8\n",
            "molded_images            shape: (1, 1024, 1024, 3)    min: -123.70000  max:  151.10000  float64\n",
            "image_metas              shape: (1, 93)               min:    0.00000  max: 1024.00000  float64\n",
            "anchors                  shape: (1, 261888, 4)        min:   -0.35390  max:    1.29134  float32\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "127.0.0.1 - - [25/Nov/2020 16:16:07] \"\u001b[37mGET /for_log HTTP/1.1\u001b[0m\" 200 -\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "test27\n",
            "Current frame pixels :  1558\n",
            "Same pixels:  1339\n",
            "Frame acc:  0.8594351732991015\n",
            "[163 163 163 ... 201 201 201] [76 77 78 ... 94 95 96]\n",
            "10\n",
            "Processing 1 images\n",
            "image                    shape: (480, 852, 3)         min:    0.00000  max:  255.00000  uint8\n",
            "molded_images            shape: (1, 1024, 1024, 3)    min: -123.70000  max:  151.10000  float64\n",
            "image_metas              shape: (1, 93)               min:    0.00000  max: 1024.00000  float64\n",
            "anchors                  shape: (1, 261888, 4)        min:   -0.35390  max:    1.29134  float32\n",
            "test27\n",
            "Current frame pixels :  1512\n",
            "Same pixels:  1266\n",
            "Frame acc:  0.8373015873015873\n",
            "[163 163 163 ... 198 198 198] [76 77 78 ... 95 96 97]\n",
            "10\n",
            "Processing 1 images\n",
            "image                    shape: (480, 852, 3)         min:    0.00000  max:  255.00000  uint8\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XO2ofjmo6mvJ"
      },
      "source": [
        "\n",
        " \n",
        " "
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}